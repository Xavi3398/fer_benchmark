{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9efdbe-e866-421e-9cb2-45695e1a2c10",
   "metadata": {},
   "source": [
    "# Unify datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a44a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from decord import VideoReader\n",
    "from decord import cpu\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "output_root = 'C:/DATASETS/AGE-FER'\n",
    "output_labels_path = os.path.join(output_root, 'datasets-labels')\n",
    "output_imgs_path = os.path.join(output_root, 'images')\n",
    "\n",
    "global_labels = ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral', 'contempt', 'pleased', 'curiosity', 'uncertainty', 'excitement', 'frustration']\n",
    "csv_columns = ['dataset','user_id','name','class','age','gender','race','perspective', 'age_group', 'subset', 'auto_age', 'auto_gender', 'auto_perspective']\n",
    "gender_names = ['female', 'male']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ce5db",
   "metadata": {},
   "source": [
    "## Common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc333d19",
   "metadata": {},
   "source": [
    "### Frame sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3cd559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(video_path, skip=.5, mode='auto', first_frame=0, max_frame=-1):\n",
    "    with open(video_path, 'rb') as f:\n",
    "        vr = VideoReader(f, ctx=cpu(0))\n",
    "        frames = frame_selection(vr.get_avg_fps(), len(vr), skip, mode, first_frame, max_frame)\n",
    "        return vr.get_batch(frames).asnumpy()[:,:,:,::-1]\n",
    "    \n",
    "def frame_selection(fps, total_frames, skip=.5, mode='auto', first_frame=0, max_frame=-1):\n",
    "    if mode == 'frame':\n",
    "        frame_skip = skip\n",
    "    elif mode == 'second':\n",
    "        frame_skip = int(fps * skip)\n",
    "    elif mode == 'part':\n",
    "        frame_skip = total_frames // (skip - 1)\n",
    "        if (total_frames % (skip - 1)) == 0:\n",
    "            frame_skip -= 1\n",
    "    elif mode == 'auto':\n",
    "        # every .5s\n",
    "        if (total_frames / fps) <= 2.5:\n",
    "            frame_skip = int(fps * .5)\n",
    "        # skip parts\n",
    "        else:\n",
    "            frame_skip = total_frames // (skip - 1)\n",
    "            if (total_frames % (skip - 1)) == 0:\n",
    "                frame_skip -= 1\n",
    "\n",
    "    frames = [i for i in range(first_frame, total_frames, frame_skip)]\n",
    "    \n",
    "    # Set last frame according to the set max frame (useful to avoid picking last frame, for example)\n",
    "    if max_frame != -1:\n",
    "        mf = len(list(range(total_frames))[:max_frame+1])\n",
    "        if frames[-1] > mf:\n",
    "            frames[-1] = mf\n",
    "    \n",
    "    return frames\n",
    "    \n",
    "def get_frames_opencv(video_path, skip=.5, mode='auto', first_frame=0, max_frame=-1):\n",
    "    cap = cv2.VideoCapture(video_path, cv2.CAP_ANY)\n",
    "    # cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('m','p','g','2'))\n",
    "    vr = VideoReader(video_path, ctx=cpu(0))\n",
    "    frames = frame_selection(vr.get_avg_fps(), len(vr), skip, mode, first_frame)\n",
    "    \n",
    "    selected_frames = np.zeros(shape=[len(frames), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), 3], dtype='uint8')\n",
    "    frame_i = 0\n",
    "    frame_selection_i =0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Finish\n",
    "        if not ret or frame_selection_i >= len(frames):\n",
    "            if frame_selection_i < len(frames):\n",
    "                selected_frames = selected_frames[:frame_selection_i,...]\n",
    "            break\n",
    "        \n",
    "        # Correct frame\n",
    "        if frames[frame_selection_i] == frame_i:\n",
    "            selected_frames[frame_selection_i,...] = frame\n",
    "            frame_selection_i += 1\n",
    "        \n",
    "        frame_i += 1\n",
    "    cap.release()\n",
    "    return selected_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3783ec",
   "metadata": {},
   "source": [
    "### Age and Gender Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_gender_videos_user(video_paths, step=1, age_mode='median', gender_mode='mode', gender_th=.3, age_max_std=None, reader='decord', mode=1):\n",
    "    \"\"\"Get average age and gender of a set of videos of the same user.\"\"\"\n",
    "    \n",
    "    ages = []\n",
    "    genders = []\n",
    "    \n",
    "    for video_path in video_paths:\n",
    "        if reader == 'decord':\n",
    "            ages2, genders2 = get_ages_genders_video(video_path, gender_name=False, step=step)\n",
    "        elif reader == 'opencv':\n",
    "            ages2, genders2 = get_ages_genders_video_opencv(video_path, gender_name=False, step=step, mode=mode)\n",
    "        ages.extend(ages2)\n",
    "        genders.extend(genders2)\n",
    "            \n",
    "    return estimate_age_gender(ages, genders, age_mode, gender_mode, gender_th, age_max_std)\n",
    "\n",
    "def get_ages_genders_video(video_path, gender_name=False, step=1, mode=1):\n",
    "    \"\"\"Get list of ages and genders of a video, each element corresponding to one frame\"\"\"\n",
    "    \n",
    "    ages = []\n",
    "    genders = []\n",
    "    \n",
    "    with open(video_path, 'rb') as f:\n",
    "        vr = VideoReader(f, ctx=cpu(0))\n",
    "        \n",
    "        for i in range(0, len(vr), step):\n",
    "            frame = vr[i].asnumpy()\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            if mode == 1:\n",
    "                age, gender = get_age_gender(frame, gender_name=False)\n",
    "            else:\n",
    "                age, gender = get_age_gender2(frame, gender_name=False)\n",
    "\n",
    "            if age is not None:\n",
    "                ages.append(age)\n",
    "                genders.append(gender)\n",
    "        \n",
    "    return ages, genders\n",
    "\n",
    "def get_ages_genders_video_opencv(video_path, gender_name=False, step=1, mode=1):\n",
    "    \"\"\"Get list of ages and genders of a video, each element corresponding to one frame\"\"\"\n",
    "    \n",
    "    ages = []\n",
    "    genders = []\n",
    "    cap = cv2.VideoCapture(video_path, cv2.CAP_ANY)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Finish\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if mode == 1:\n",
    "            age, gender = get_age_gender(frame, gender_name=False)\n",
    "        else:\n",
    "            age, gender = get_age_gender2(frame, gender_name=False)\n",
    "\n",
    "        if age is not None:\n",
    "            ages.append(age)\n",
    "            genders.append(gender)\n",
    "            \n",
    "    cap.release()\n",
    "    return ages, genders\n",
    "\n",
    "def get_age_gender_imgs_user(img_paths, age_mode='median', gender_mode='mode', gender_th=.3, age_max_std=None, mode=1):\n",
    "    \"\"\"Get average age and gender of a set of images of the same user.\"\"\"\n",
    "    \n",
    "    ages = []\n",
    "    genders = []\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "    \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print('Error al abrir la imagen:', img_path)\n",
    "            continue\n",
    "        \n",
    "        if mode == 1:\n",
    "            age, gender = get_age_gender(img, gender_name=False)\n",
    "        else:\n",
    "            age, gender = get_age_gender2(img, gender_name=False)\n",
    "        if age is not None:\n",
    "            ages.append(age)\n",
    "            genders.append(gender)\n",
    "            \n",
    "    return estimate_age_gender(ages, genders, age_mode, gender_mode, gender_th, age_max_std)\n",
    "\n",
    "def estimate_age_gender(ages, genders, age_mode='median', gender_mode='mode', gender_th=.3, age_max_std=None):\n",
    "    \n",
    "    # Gender\n",
    "    if len(genders) < 1:\n",
    "        gender = None\n",
    "    elif gender_mode == 'mode':\n",
    "        genders_mean = np.mean(genders)\n",
    "        gender = gender_names[round(genders_mean)] if len(genders) > 0 and (genders_mean <= gender_th or genders_mean >= (1-gender_th)) else None\n",
    "    else:\n",
    "        print('Wrong gender mode')\n",
    "        gender = None\n",
    "    \n",
    "    # Age\n",
    "    if len(ages) < 1:\n",
    "        age = None\n",
    "    elif age_mode == 'mean':\n",
    "        age = round(np.mean(ages))\n",
    "    elif age_mode == 'median':\n",
    "        age = round(np.median(ages))\n",
    "    else:\n",
    "        print('Wrong gender mode')\n",
    "        age = None\n",
    "        \n",
    "    if age_max_std is not None and len(ages) > 0:\n",
    "        if np.std(ages) > age_max_std:\n",
    "            age = None\n",
    "    \n",
    "    return age, gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded005a2",
   "metadata": {},
   "source": [
    "Using MiVOLO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa87a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mivolo.predictor import Predictor\n",
    "from mivolo.model.mi_volo import MiVOLO\n",
    "from mivolo.data.misc import prepare_classification_images\n",
    "import torch\n",
    "\n",
    "class Config():\n",
    "    def __init__(self, detector_weights, checkpoint, device, with_persons, disable_faces, draw):\n",
    "        self.detector_weights = detector_weights\n",
    "        self.checkpoint = checkpoint\n",
    "        self.device = device\n",
    "        self.with_persons = with_persons\n",
    "        self.disable_faces = disable_faces\n",
    "        self.draw = draw\n",
    "        \n",
    "config = Config(\n",
    "    detector_weights=\"../weights/yolov8x_person_face.pt\",\n",
    "    checkpoint=\"../weights/mivolo_imbd.pth.tar\",\n",
    "    device=\"cuda:0\",\n",
    "    with_persons=True,\n",
    "    disable_faces=False,\n",
    "    draw = False\n",
    ")\n",
    "predictor = Predictor(config, verbose=False)\n",
    "recognizer = predictor.age_gender_model\n",
    "\n",
    "def get_age_gender(img, gender_name=True):\n",
    "    \"\"\"Get age and gender of an image.\"\"\"\n",
    "    \n",
    "    detected_objects, _ = predictor.recognize(img)\n",
    "    \n",
    "    # No faces and no persons detected\n",
    "    if len(detected_objects.ages) == 0 and len(detected_objects.genders) == 0:\n",
    "        print('No faces nor persons found.')\n",
    "        return None, None\n",
    "    \n",
    "    age = detected_objects.ages[0]\n",
    "    gender = detected_objects.genders[0]\n",
    "    if not gender_name:\n",
    "        if gender == 'male':\n",
    "            gender = 1\n",
    "        elif gender == 'female':\n",
    "            gender = 0\n",
    "\n",
    "    return age, gender\n",
    "\n",
    "def get_age_gender2(img, gender_name=True):\n",
    "    \"\"\"Get age and gender of an image without detection.\"\"\"\n",
    "    \n",
    "    # Prepare image for classification\n",
    "    img = prepare_classification_images([img.astype(np.uint8)], recognizer.input_size, recognizer.data_config[\"mean\"], recognizer.data_config[\"std\"], device=recognizer.device)\n",
    "    img = torch.cat((img, img), dim=1)\n",
    "\n",
    "    # Recognize emotions\n",
    "    output = recognizer.inference(img)\n",
    "    \n",
    "    if recognizer.meta.only_age:\n",
    "        age_output = output\n",
    "        gender_probs, gender_indx = None, None\n",
    "    else:\n",
    "        age_output = output[:, 2]\n",
    "        gender_output = output[:, :2].softmax(-1)\n",
    "        gender_probs, gender_indx = gender_output.topk(1)\n",
    "        \n",
    "    # get age\n",
    "    age = age_output[0].item()\n",
    "    age = age * (recognizer.meta.max_age - recognizer.meta.min_age) + recognizer.meta.avg_age\n",
    "    age = round(age)\n",
    "\n",
    "    # get gender\n",
    "    if gender_probs is not None:\n",
    "        gender = \"male\" if gender_indx[0].item() == 0 else \"female\"\n",
    "    \n",
    "    if not gender_name:\n",
    "        if gender == 'male':\n",
    "            gender = 1\n",
    "        elif gender == 'female':\n",
    "            gender = 0\n",
    "\n",
    "    return age, gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd236c38",
   "metadata": {},
   "source": [
    "### Head Pose and Facial Landmarks Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_to_text(pose):\n",
    "    \"\"\"Convert pose to text.\"\"\"\n",
    "    \n",
    "    if pose is None:\n",
    "        return None\n",
    "    elif pose[1] < 22.5 and pose[1] > -22.5:\n",
    "        return 'front'\n",
    "    elif pose[1] > 0 and pose[1] < 67.5:\n",
    "        return 'half_right'\n",
    "    elif pose[1] < 0 and pose[1] > -67.5:\n",
    "        return 'half_left'\n",
    "    elif pose[1] > 0 and pose[1] < 112.5:\n",
    "        return 'full_right'\n",
    "    elif pose[1] < 0 and pose[1] > -112.5:\n",
    "        return 'full_left'\n",
    "    else:\n",
    "        return 'back'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae50484",
   "metadata": {},
   "source": [
    "Using SPIGA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b020b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.yolo.engine.model import YOLO\n",
    "from spiga.inference.config import ModelConfig\n",
    "from spiga.inference.framework import SPIGAFramework\n",
    "\n",
    "weights = '../weights/yolov8x_person_face.pt'\n",
    "yolo = YOLO(weights)\n",
    "yolo.fuse()\n",
    "\n",
    "dataset = 'wflw'\n",
    "cfg = ModelConfig(dataset)\n",
    "cfg.load_model_url = None\n",
    "cfg.model_weights_path = '../weights'\n",
    "cfg.model_weights = 'spiga_wflw.pt'\n",
    "processor = SPIGAFramework(cfg)\n",
    "\n",
    "def get_bbox_hw(img):\n",
    "    # YOLO detect face\n",
    "    yolo_pred = yolo(img, conf=.4, iou=.7, half=True, verbose=False)\n",
    "    \n",
    "    if len(yolo_pred) < 1:\n",
    "        return None\n",
    "    \n",
    "    yolo_pred = yolo_pred[0].boxes\n",
    "    classes = yolo_pred.cls.numpy(force=True)\n",
    "    bboxes = yolo_pred.xyxy.numpy(force=True)\n",
    "    \n",
    "    if not 1 in classes:\n",
    "        return None\n",
    "    \n",
    "    face_bbox = bboxes[np.where(classes == 1)[0]][0].astype('int')\n",
    "    face_bbox_hw = np.array([face_bbox[0], face_bbox[1], face_bbox[2] - face_bbox[0], face_bbox[3] - face_bbox[1]])\n",
    "    return face_bbox_hw\n",
    "\n",
    "def get_spiga_feature(img, use_detector=True, feature='landmarks'):\n",
    "    \n",
    "    if use_detector:\n",
    "        face_bbox_hw = get_bbox_hw(img)\n",
    "    else:\n",
    "        face_bbox_hw = [0, 0, img.shape[1], img.shape[0]]\n",
    "    \n",
    "    if face_bbox_hw is None:\n",
    "        return None\n",
    "\n",
    "    features = processor.inference(img, [face_bbox_hw])\n",
    "    return np.array(features[feature][0])\n",
    "\n",
    "def get_keypoints(img, use_detector=True):\n",
    "    landmarks = get_spiga_feature(img, use_detector, 'landmarks')\n",
    "    return [np.mean(landmarks[60:68], axis=0), np.mean(landmarks[68:76], axis=0), landmarks[53], landmarks[88], landmarks[92]]\n",
    "\n",
    "def get_pose(img, use_detector=True):\n",
    "    return get_spiga_feature(img, use_detector, 'headpose')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aba501",
   "metadata": {},
   "source": [
    "# Label the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee963d46",
   "metadata": {},
   "source": [
    "## AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'AffectNet'\n",
    "input_path = 'C:/DATASETS/AffectNetUniques'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "duplicates_csv = os.path.join(input_path, 'annotations_IJIMAI.csv')\n",
    "labels = ['neutral','happiness','sadness','surprise','fear','disgust','anger','contempt']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "# Build dict with duplicates. Use name as key\n",
    "duplicates = {}\n",
    "with open(duplicates_csv, 'r') as f:\n",
    "\n",
    "    # Read csv as dict\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        duplicates[(row['folder'] + '_' + row['name']).upper()] = {'gender': row['gender'], 'duplicated': True if row['duplicated'] == 'True' else False}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for class_i, label in enumerate(labels):\n",
    "        for img_name in os.listdir(os.path.join(input_path, str(class_i))):\n",
    "\n",
    "            # Check if duplicate or if gender is annotated\n",
    "            gender = None\n",
    "            if img_name.upper() in duplicates:\n",
    "                \n",
    "                # If duplicate, skip\n",
    "                if duplicates[img_name]['duplicated']:\n",
    "                    continue\n",
    "                else:\n",
    "                    gender = duplicates[img_name]['gender']\n",
    "                    if gender == 'M':\n",
    "                        gender = 'male'\n",
    "                    elif gender == 'F':\n",
    "                        gender = 'female'\n",
    "                    else:\n",
    "                        gender = None\n",
    "            \n",
    "            # User ID\n",
    "            row_id = id_counter\n",
    "            if row_id in users:\n",
    "                user_id = users[row_id][0]['user_id']\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users[row_id] = []\n",
    "                id_counter += 1\n",
    "\n",
    "            users[row_id].append({\n",
    "                'dataset': dataset_name, \n",
    "                'user_id': None, #user_id,\n",
    "                'name': img_name,\n",
    "                'class': label,\n",
    "                'age': None,\n",
    "                'gender': gender,\n",
    "                'race': None,\n",
    "                'perspective': None,\n",
    "                'age_group': None,\n",
    "                'subset': None,\n",
    "                'auto_age': 0,\n",
    "                'auto_gender': 0,\n",
    "                'auto_perspective': 0,\n",
    "                'img_path': os.path.join(input_path, str(class_i), img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, gender = get_age_gender_imgs_user([row['img_path'] for row in user], mode=2)\n",
    "        for row in user:\n",
    "\n",
    "            img_path = row.pop('img_path')\n",
    "            perspective = pose_to_text(get_pose(cv2.imread(img_path), use_detector=False))\n",
    "\n",
    "            row['auto_age'] = 1 if age is not None else 0\n",
    "            row['age'] = age\n",
    "            row['auto_gender'] = 1 if gender is not None else 0\n",
    "            row['gender'] = gender\n",
    "            row['auto_perspective'] = 1 if perspective is not None else 0\n",
    "            row['perspective'] = perspective\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9731f5ba",
   "metadata": {},
   "source": [
    "## NHFI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd7e3a",
   "metadata": {},
   "source": [
    "Images with same name at different label folders. Renamed to \"label_img-name.png\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8474af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'NHFI'\n",
    "input_path = 'C:/DATASETS/NHFI'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['sadness', 'neutrality', 'anger', 'disgust','surprise','fear', 'happiness', 'contempt']\n",
    "labels_out = ['sadness', 'neutral', 'anger', 'disgust','surprise','fear', 'happiness', 'contempt']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for label in labels_in:\n",
    "        for img_name in os.listdir(os.path.join(input_path, label)):\n",
    "            \n",
    "            # User ID\n",
    "            row_id = id_counter\n",
    "            if row_id in users:\n",
    "                user_id = users[row_id][0]['user_id']\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users[row_id] = []\n",
    "                id_counter += 1\n",
    "\n",
    "            users[row_id].append({\n",
    "                'dataset': dataset_name, \n",
    "                'user_id': None, # user_id,\n",
    "                'name': label + '_' + img_name,\n",
    "                'class': labels_out[labels_in.index(label)],\n",
    "                'age': None,\n",
    "                'gender': None,\n",
    "                'race': None,\n",
    "                'perspective': None, \n",
    "                'age_group': None,\n",
    "                'subset': None,\n",
    "                'auto_age': 0,\n",
    "                'auto_gender': 0,\n",
    "                'auto_perspective': 0,\n",
    "                'img_path': os.path.join(input_path, label, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, gender = get_age_gender_imgs_user([row['img_path'] for row in user], mode=2)\n",
    "        for row in user:\n",
    "\n",
    "            img_path = row.pop('img_path')\n",
    "            perspective = pose_to_text(get_pose(cv2.imread(img_path), use_detector=False))\n",
    "\n",
    "            row['auto_age'] = 1 if row['age'] is None and age is not None else 0\n",
    "            row['age'] = age\n",
    "            row['auto_gender'] = 1 if row['gender'] is None and gender is not None else 0\n",
    "            row['gender'] = gender\n",
    "            row['auto_perspective'] = 1 if row['perspective'] is None and perspective is not None else 0\n",
    "            row['perspective'] = perspective\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a70522",
   "metadata": {},
   "source": [
    "## RAF-DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'RAF-DB'\n",
    "input_path = 'C:/DATASETS/RAF-DB/DATASET'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['5', '7', '6', '3', '1', '2', '4']\n",
    "labels_out = ['sadness', 'neutral', 'anger', 'disgust','surprise','fear', 'happiness']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for split in ['train', 'test']:\n",
    "        for label in labels_in:\n",
    "            for img_name in os.listdir(os.path.join(input_path, split, label)):\n",
    "                \n",
    "                # User ID\n",
    "                row_id = id_counter\n",
    "                if row_id in users:\n",
    "                    user_id = users[row_id][0]['user_id']\n",
    "                else:\n",
    "                    user_id = dataset_name + '-' + str(id_counter)\n",
    "                    users[row_id] = []\n",
    "                    id_counter += 1\n",
    "\n",
    "                users[row_id].append({\n",
    "                    'dataset': dataset_name, \n",
    "                    'user_id': None, # user_id,\n",
    "                    'name': img_name,\n",
    "                    'class': labels_out[labels_in.index(label)],\n",
    "                    'age': None,\n",
    "                    'gender': None,\n",
    "                    'race': None,\n",
    "                    'perspective': None, \n",
    "                    'age_group': None,\n",
    "                    'subset': split,\n",
    "                    'auto_age': 0,\n",
    "                    'auto_gender': 0,\n",
    "                    'auto_perspective': 0,\n",
    "                    'img_path': os.path.join(input_path, split, label, img_name)})\n",
    "        \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, gender = get_age_gender_imgs_user([row['img_path'] for row in user], mode=2)\n",
    "        for row in user:\n",
    "\n",
    "            img_path = row.pop('img_path')\n",
    "            perspective = pose_to_text(get_pose(cv2.imread(img_path), use_detector=False))\n",
    "\n",
    "            row['auto_age'] = 1 if row['age'] is None and age is not None else 0\n",
    "            row['age'] = age\n",
    "            row['auto_gender'] = 1 if row['gender'] is None and gender is not None else 0\n",
    "            row['gender'] = gender\n",
    "            row['auto_perspective'] = 1 if row['perspective'] is None and perspective is not None else 0\n",
    "            row['perspective'] = perspective\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a063de0",
   "metadata": {},
   "source": [
    "## DDCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b97d83",
   "metadata": {},
   "source": [
    "- First merge folders 40males and 40femaleses\n",
    "- Delete folders \"edited\" for some subjects\n",
    "- Pleased considered as \"happiness\" expression\n",
    "- Race: caucasian, according to article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550af5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'DDCF'\n",
    "input_path = 'C:/DATASETS/DDCF'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['Afraid','Angry','Disgusted','Happy','Neutral','Pleased','Sad','Surprised']\n",
    "labels_out = ['fear','anger','disgust','happiness','neutral','pleased','sadness','surprise']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for class_i, label in enumerate(labels_in):\n",
    "        for dir_name in os.listdir(os.path.join(input_path, label)):\n",
    "            \n",
    "            for img_name in os.listdir(os.path.join(input_path, label, dir_name)):\n",
    "        \n",
    "                # User ID\n",
    "                if dir_name in users:\n",
    "                    user_id = users[dir_name]\n",
    "                else:\n",
    "                    user_id = dataset_name + '-' + str(id_counter)\n",
    "                    users[dir_name] = user_id\n",
    "                    id_counter += 1\n",
    "                \n",
    "                # Gender\n",
    "                gender = img_name.split('_')[1].split('yo')[1]\n",
    "                if gender == 'F' or gender == 'f':\n",
    "                    gender = 'female'\n",
    "                elif gender == 'M' or gender == 'm':\n",
    "                    gender = 'male'\n",
    "                else:\n",
    "                    gender = None\n",
    "                    print('Gender error:', img_name)\n",
    "                \n",
    "                # Perspective\n",
    "                perspective = None\n",
    "                if 'far right' in img_name:\n",
    "                    perspective = 'full_right'\n",
    "                elif 'far left' in img_name:\n",
    "                    perspective = 'full_left'\n",
    "                elif 'front' in img_name or 'Front' in img_name:\n",
    "                    perspective = 'front'\n",
    "                elif 'right' in img_name:\n",
    "                    perspective = 'half_right'\n",
    "                elif 'left' in img_name:\n",
    "                    perspective = 'half_left'\n",
    "                else:\n",
    "                    print(img_name)\n",
    "                    \n",
    "                spamwriter.writerow({\n",
    "                    'dataset': dataset_name, \n",
    "                    'user_id': user_id,\n",
    "                    'name': img_name,\n",
    "                    'class': labels_out[class_i],\n",
    "                    'age': img_name.split('_')[1].split('yo')[0],\n",
    "                    'gender': gender,\n",
    "                    'race': 'caucasian',\n",
    "                    'perspective': perspective, \n",
    "                    'age_group': None,\n",
    "                    'subset': None,\n",
    "                    'auto_age': 0,\n",
    "                    'auto_gender': 0,\n",
    "                    'auto_perspective': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8739fad",
   "metadata": {},
   "source": [
    "## DEFSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e987bdf",
   "metadata": {},
   "source": [
    "- First convert \"Model Descriptives.xlsx\" to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37756c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'DEFSS'\n",
    "input_path = 'C:/DATASETS/DEFSS'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['Happy','Sad','Fear','Angry','Neutral']\n",
    "labels_out = ['happiness','sadness','fear','anger','neutral']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile, open(os.path.join(input_path, 'Photo Descriptives.csv'), 'r') as csvfile_input:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    reader = csv.DictReader(csvfile_input, delimiter=';')\n",
    "    for row in reader:\n",
    "        \n",
    "        # User ID\n",
    "        if row['ID'] in users:\n",
    "            user_id = users[row['ID']]\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row['ID']] = user_id\n",
    "            id_counter += 1\n",
    "        \n",
    "        # File name, fixing some naming errors\n",
    "        file_name = row['ID']+'_'+row['Sex']+row['Age']+'_'+row['Emotion']+'.jpg'\n",
    "        if not os.path.exists(os.path.join(input_path, 'images', file_name)):\n",
    "            file_name = row['ID']+'_'+row['Age']+row['Sex']+'_'+row['Emotion']+'.jpg'\n",
    "            if not os.path.exists(os.path.join(input_path, 'images', file_name)):\n",
    "                file_name = row['ID']+'_'+row['Sex']+row['Age']+'_'+row['Emotion']+'_s.jpg'\n",
    "                if not os.path.exists(os.path.join(input_path, 'images', file_name)):\n",
    "                    print('Not found:', file_name)\n",
    "                  \n",
    "        # Gender\n",
    "        gender = row['Sex']\n",
    "        if gender == 'F' or gender == 'f':\n",
    "            gender = 'female'\n",
    "        elif gender == 'M' or gender == 'm':\n",
    "            gender = 'male'\n",
    "        else:\n",
    "            gender = None\n",
    "            print('Gender error:', img_name)\n",
    "\n",
    "        # Race\n",
    "        race = row['Race'].lower()\n",
    "        if race == 'black/white':\n",
    "            race = None\n",
    "        elif race == 'native/white':\n",
    "            race = 'white'\n",
    "        elif race == 'other':\n",
    "            race = None\n",
    "        elif race == 'not identified':\n",
    "            race = None\n",
    "        elif race not in ['black', 'white', 'hispanic', 'asian']:\n",
    "            print(file_name, race)\n",
    "                    \n",
    "        spamwriter.writerow({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'name': file_name,\n",
    "            'class': labels_out[labels_in.index(row['Emotion'])],\n",
    "            'age': row['Age'],\n",
    "            'gender': gender,\n",
    "            'race': race,\n",
    "            'perspective': 'front', \n",
    "            'age_group': None,\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef37e0b",
   "metadata": {},
   "source": [
    "## FACES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23de4d1-f259-4f98-923e-287e57110ac4",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Race: caucasian, according to article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'FACES'\n",
    "input_path = 'C:/DATASETS/FACES/FACES'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['a','d','f','h','n','s',]\n",
    "labels_out = ['anger','disgust','fear','happiness','neutral','sadness']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for img_name in os.listdir(os.path.join(input_path)):\n",
    "        img_name_split = img_name.split('_')\n",
    "            \n",
    "        # Gender\n",
    "        gender = img_name_split[2]\n",
    "        if gender == 'F' or gender == 'f':\n",
    "            gender = 'female'\n",
    "        elif gender == 'M' or gender == 'm':\n",
    "            gender = 'male'\n",
    "        else:\n",
    "            gender = None\n",
    "            print('Gender error:', img_name)\n",
    "            \n",
    "        # Age group\n",
    "        age_group = img_name_split[1]\n",
    "        if age_group == 'o':\n",
    "            age_group = 'elderly'\n",
    "        elif age_group == 'y':\n",
    "            age_group = 'young'\n",
    "        elif age_group == 'm':\n",
    "            age_group = 'middle-age'\n",
    "        else:\n",
    "            age_group = None\n",
    "            print('Age group error')\n",
    "        \n",
    "        # User ID\n",
    "        row_id = img_name_split[0]\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "            \n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'name': img_name,\n",
    "            'class': labels_out[labels_in.index(img_name_split[3])],\n",
    "            'age': None,\n",
    "            'gender': gender,\n",
    "            'race': 'caucasian',\n",
    "            'perspective': 'front', \n",
    "            'age_group': age_group,\n",
    "            'subset': None,\n",
    "            'auto_age': 1,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_imgs_user([os.path.join(input_path, row['name']) for row in user])\n",
    "        for row in user:\n",
    "            row['age'] = age\n",
    "            row['auto_age'] = 1 if age is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240e3e7",
   "metadata": {},
   "source": [
    "## NIMH-ChEFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94342d",
   "metadata": {},
   "source": [
    "- Afraid_averted/DSC_4644.JPG deleted, since it is repeated with another name (M2FA_4644.jpg)\n",
    "- Naming error: F6_2FA_5449.jpg changed to M6_2FA_5449.jpg, M6FA__5449.jpg changed to M6_3FA_5449.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a90bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'NIMH-ChEFS'\n",
    "input_path = 'C:/DATASETS/NIMH-ChEFS'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['Angry','Afraid','Happy','Neutral','Sad',]\n",
    "labels_out = ['anger','fear','happiness','neutral','sadness']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for dir_name in os.listdir(os.path.join(input_path)):\n",
    "        for img_name in os.listdir(os.path.join(input_path, dir_name)):\n",
    "\n",
    "            # Gender\n",
    "            gender = img_name[0]\n",
    "            if gender == 'F' or gender == 'f':\n",
    "                gender = 'female'\n",
    "            elif gender == 'M' or gender == 'm':\n",
    "                gender = 'male'\n",
    "            else:\n",
    "                gender = None\n",
    "                print('Gender error:', img_name)\n",
    "            \n",
    "            # Perspective\n",
    "            perspective = dir_name.split('_')[1]\n",
    "            if perspective == 'direct':\n",
    "                perspective = 'front'\n",
    "            elif perspective == 'averted':\n",
    "                perspective = 'averted_gaze'\n",
    "            else:\n",
    "                perspective = None\n",
    "                print('Perspective error')\n",
    "        \n",
    "            # User ID\n",
    "            if len(img_name.split('_')[0]) == 2:\n",
    "                row_id = img_name[0:2]\n",
    "            elif len(img_name.split('_')[0]) == 3:\n",
    "                row_id = img_name[0:3]\n",
    "            elif len(img_name.split('_')[0]) == 4:\n",
    "                row_id = img_name[0:2]\n",
    "            elif len(img_name.split('_')[0]) == 5:\n",
    "                row_id = img_name[0:3]\n",
    "                \n",
    "            if row_id in users:\n",
    "                user_id = users[row_id][0]['user_id']\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users[row_id] = []\n",
    "                id_counter += 1\n",
    "\n",
    "            users[row_id].append({\n",
    "                'dataset': dataset_name, \n",
    "                'user_id': user_id,\n",
    "                'name': img_name,\n",
    "                'class': labels_out[labels_in.index(dir_name.split('_')[0])],\n",
    "                'age': None,\n",
    "                'gender': gender,\n",
    "                'race': None,\n",
    "                'perspective': perspective, \n",
    "                'age_group': '10-17',\n",
    "                'subset': None,\n",
    "                'auto_age': 0,\n",
    "                'auto_gender': 0,\n",
    "                'auto_perspective': 0,\n",
    "                'img_path': os.path.join(input_path, dir_name, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_imgs_user([row.pop('img_path') for row in user])\n",
    "        for row in user:\n",
    "            row['age'] = np.clip(age, 10, 17) if age is not None else None\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32c9fe2",
   "metadata": {},
   "source": [
    "## RaFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c50955f-160c-4fa9-bb6a-960e52af85f2",
   "metadata": {},
   "source": [
    "- age_group = child or adult. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8985b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'RaFD'\n",
    "input_path = 'C:/DATASETS/RaFD'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['sad', 'neutral', 'angry', 'contemptuous', 'disgusted', 'surprised', 'fearful', 'happy']\n",
    "labels_out = ['sadness', 'neutral', 'anger', 'contempt', 'disgust','surprise','fear', 'happiness']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for img_name in os.listdir(os.path.join(input_path)):\n",
    "        img_name_split = img_name.split('_')\n",
    "            \n",
    "        # Perspective\n",
    "        perspective_1 = img_name_split[0]\n",
    "        if perspective_1 == 'Rafd000':\n",
    "            perspective_1 = 'full_left'\n",
    "        elif perspective_1 == 'Rafd045':\n",
    "            perspective_1 = 'half_left'\n",
    "        elif perspective_1 == 'Rafd090':\n",
    "            perspective_1 = 'front'\n",
    "        elif perspective_1 == 'Rafd135':\n",
    "            perspective_1 = 'half_right'\n",
    "        elif perspective_1 == 'Rafd180':\n",
    "            perspective_1 = 'full_right'\n",
    "        else:\n",
    "            perspective_1 = None\n",
    "            print('Perspective error:', img_name)\n",
    "            \n",
    "        perspective_2 = img_name_split[5].split('.')[0]\n",
    "        if perspective_2 == 'left':\n",
    "            perspective_2 = '_gaze_left'\n",
    "        elif perspective_2 == 'right':\n",
    "            perspective_2 = '_gaze_right'\n",
    "        elif perspective_2 == 'frontal':\n",
    "            perspective_2 = ''\n",
    "        else:\n",
    "            perspective_2 = None\n",
    "            print('Perspective error:', img_name)\n",
    "        \n",
    "        perspective = (perspective_1 if perspective_1 is not None else '') + (perspective_2 if perspective_2 is not None else '')\n",
    "        \n",
    "        # Race\n",
    "        race = img_name_split[2].lower()\n",
    "        if race == 'kid':\n",
    "            race = 'caucasian'\n",
    "        elif race != 'caucasian' and race != 'moroccan':\n",
    "            print('Error in race:', img_name)\n",
    "        \n",
    "        # Age group\n",
    "        if img_name_split[2].lower() == 'kid':\n",
    "            age_group = 'kid'\n",
    "        else:\n",
    "            age_group = 'adult'\n",
    "        \n",
    "        # User ID\n",
    "        row_id = img_name_split[1]\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'name': img_name,\n",
    "            'class': labels_out[labels_in.index(img_name_split[4])],\n",
    "            'age': None,\n",
    "            'gender': img_name_split[3],\n",
    "            'race': race,\n",
    "            'perspective': perspective,\n",
    "            'age_group': age_group,\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0,\n",
    "            'img_path': os.path.join(input_path, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_imgs_user([row.pop('img_path') for row in user])\n",
    "        for row in user:\n",
    "            row['age'] = age\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4f53f",
   "metadata": {},
   "source": [
    "## FER2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'FER2013'\n",
    "input_path = 'C:/DATASETS/FER2013'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['Sad', 'Neutral', 'Angry', 'Disgust','Surprise','Fear', 'Happy']\n",
    "labels_out = ['sadness', 'neutral', 'anger', 'disgust','surprise','fear', 'happiness']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for label in labels_in:\n",
    "        for img_name in os.listdir(os.path.join(input_path, label)):\n",
    "            \n",
    "            # User ID\n",
    "            row_id = id_counter\n",
    "            if row_id in users:\n",
    "                user_id = users[row_id][0]['user_id']\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users[row_id] = []\n",
    "                id_counter += 1\n",
    "\n",
    "            users[row_id].append({\n",
    "                'dataset': dataset_name, \n",
    "                'user_id': None, # user_id,\n",
    "                'name': img_name,\n",
    "                'class': labels_out[labels_in.index(label)],\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'race': None,\n",
    "                'perspective': None, \n",
    "                'age_group': None,\n",
    "                'subset': None,\n",
    "                'auto_age': 0,\n",
    "                'auto_gender': 0,\n",
    "                'auto_perspective': 0,\n",
    "                'img_path': os.path.join(input_path, label, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, gender = get_age_gender_imgs_user([row['img_path'] for row in user], mode=2)\n",
    "        for row in user:\n",
    "\n",
    "            img_path = row.pop('img_path')\n",
    "            perspective = pose_to_text(get_pose(cv2.imread(img_path), use_detector=False))\n",
    "\n",
    "            row['auto_age'] = 1 if row['age'] is None and age is not None else 0\n",
    "            row['age'] = age\n",
    "            row['auto_gender'] = 1 if row['gender'] is None and gender is not None else 0\n",
    "            row['gender'] = gender\n",
    "            row['auto_perspective'] = 1 if row['perspective'] is None and perspective is not None else 0\n",
    "            row['perspective'] = perspective\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5331ca2",
   "metadata": {},
   "source": [
    "## ExpW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ExpW'\n",
    "input_path = 'C:/DATASETS/ExpW'\n",
    "imgs_path = 'C:/DATASETS/ExpW/origin'\n",
    "cropped_imgs_path = 'C:/DATASETS/ExpW/cropped'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_in =  ['4', '6', '0', '1','5','2', '3']\n",
    "labels_out = ['sadness', 'neutral', 'anger', 'disgust','surprise','fear', 'happiness']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile, open(os.path.join(input_path, 'label.lst'), 'r') as csvfile_input:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    reader = csv.DictReader(csvfile_input, delimiter=' ')\n",
    "    \n",
    "    for row in tqdm(reader):\n",
    "        \n",
    "        img_name = row['image_name']\n",
    "        new_img_name = str(id_counter) + '_' + img_name\n",
    "        img = cv2.imread(os.path.join(imgs_path, img_name))\n",
    "        \n",
    "        # Square crop img\n",
    "        top = int(row['face_box_top'])\n",
    "        left = int(row['face_box_left'])\n",
    "        bottom = int(row['face_box_bottom'])\n",
    "        right = int(row['face_box_right'])\n",
    "\n",
    "        crop_size = max(right - left, bottom - top)\n",
    "        top = max(0, top - (crop_size - (bottom - top)) // 2)\n",
    "        left = max(0, left - (crop_size - (right - left)) // 2)\n",
    "        bottom = min(img.shape[0], top + crop_size)\n",
    "        right = min(img.shape[1], left + crop_size)\n",
    "\n",
    "        img = img[top:bottom, left:right]\n",
    "\n",
    "        # Save cropped image\n",
    "        cv2.imwrite(os.path.join(cropped_imgs_path, new_img_name), img)\n",
    "\n",
    "        # Estimate age and gender\n",
    "        age, gender = get_age_gender2(img)\n",
    "        perspective = pose_to_text(get_pose(img, use_detector=False))\n",
    "\n",
    "        spamwriter.writerow({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': None, # user_id,\n",
    "            'name': new_img_name,\n",
    "            'class': labels_out[labels_in.index(row['expression_label'])],\n",
    "            'age': age,\n",
    "            'gender': gender,\n",
    "            'race': None,\n",
    "            'perspective': perspective, \n",
    "            'age_group': None,\n",
    "            'subset': None,\n",
    "            'auto_age': 1 if age is not None else 0,\n",
    "            'auto_gender': 1 if gender is not None else 0,\n",
    "            'auto_perspective': 1 if perspective is not None else 0})\n",
    "        \n",
    "        id_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7916384",
   "metadata": {},
   "source": [
    "## WSEFEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d05bb5",
   "metadata": {},
   "source": [
    "- First convert \"WSEFEP - norms & FACS.xlsx\" to CSV\n",
    "- Added \"MG_0850.jpg\" to the CSV, because the image existed but the label did not\n",
    "- Changed \"MG_1317.jpg\" to \"MG_1317.JPG\" in CSV\n",
    "- Changed \"AD_8286.jpg\" to \"AD_8268.jpg\" in CSV\n",
    "- Changed \"JS_0491.jpg\" to \"JS_0449.jpg\" in CSV\n",
    "- Changed \"SO_0052.jpg\" to \"SO_0053.jpg\" in CSV\n",
    "- race = 'polish', according to article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'WSEFEP'\n",
    "input_path = 'C:/DATASETS/WSEFEP'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'joy': 'happiness',\n",
    "    'sadness': 'sadness',\n",
    "    'fear': 'fear',\n",
    "    'anger': 'anger',\n",
    "    'neutral': 'neutral', \n",
    "    'surprise': 'surprise', \n",
    "    'disgust': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile, open(os.path.join(input_path, 'WSEFEP - norms & FACS.csv'), 'r') as csvfile_input:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    reader = csv.DictReader(csvfile_input, delimiter=';')\n",
    "    for row in reader:\n",
    "        \n",
    "        # File name, fixing some naming errors\n",
    "        file_name = row['Picture ID']\n",
    "        if not os.path.exists(os.path.join(input_path, 'images', file_name)):\n",
    "            print('Not found:', file_name)\n",
    "                  \n",
    "        # Gender\n",
    "        gender = row['Male/ Female']\n",
    "        if gender == 'F' or gender == 'f':\n",
    "            gender = 'female'\n",
    "        elif gender == 'M' or gender == 'm':\n",
    "            gender = 'male'\n",
    "        else:\n",
    "            gender = None\n",
    "            print('Gender error:', row)\n",
    "        \n",
    "        # User ID\n",
    "        row_id = row['Displayer ID']\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'name': file_name,\n",
    "            'class': labels_dict[row['Display']],\n",
    "            'age': None,\n",
    "            'gender': gender,\n",
    "            'race': 'polish',\n",
    "            'perspective': 'front', \n",
    "            'age_group': '20-30',\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0,\n",
    "            'img_path': os.path.join(input_path, 'images', file_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_imgs_user([row.pop('img_path') for row in user])\n",
    "        for row in user:\n",
    "            row['age'] = np.clip(age, 20, 30) if age is not None else None\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a9f03",
   "metadata": {},
   "source": [
    "## KDEF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9300e1d",
   "metadata": {},
   "source": [
    "- Deleted black images: AF01SUFR, AF10AFFR, AF11NEHL, AF20DIHL, AM25DIFL, AM34DIFR, BF13NEHR, BM21DIFL, BM22DIHL, BM24DIFL\n",
    "- Deleted too bright images: AM17DIHR, BM17NES\n",
    "- Deleted corrupted images: AM02HAFR\n",
    "- Renamed: \"AF31V.JPG\" to \"AF31SAHL.JPG\", \"AM31H.JPG\" to \"AM31SUHR.JPG\"\n",
    "- race = swedish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abceaf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'KDEF'\n",
    "input_path = 'C:/DATASETS/KDEF/images'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'HA': 'happiness',\n",
    "    'SA': 'sadness',\n",
    "    'AF': 'fear',\n",
    "    'AN': 'anger',\n",
    "    'NE': 'neutral', \n",
    "    'SU': 'surprise', \n",
    "    'DI': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for dir_name in os.listdir(os.path.join(input_path)):\n",
    "        for img_name in os.listdir(os.path.join(input_path, dir_name)):\n",
    "\n",
    "            # Gender\n",
    "            gender = dir_name[1]\n",
    "            if gender == 'F' or gender == 'f':\n",
    "                gender = 'female'\n",
    "            elif gender == 'M' or gender == 'm':\n",
    "                gender = 'male'\n",
    "            else:\n",
    "                gender = None\n",
    "                print('Gender error:', img_name)\n",
    "            \n",
    "            # Perspective\n",
    "            perspective = img_name[6:8]\n",
    "            if perspective == 'FL':\n",
    "                perspective = 'full_left'\n",
    "            elif perspective == 'FR':\n",
    "                perspective = 'full_right'\n",
    "            elif perspective == 'HL':\n",
    "                perspective = 'half_left'\n",
    "            elif perspective == 'HR':\n",
    "                perspective = 'half_right'\n",
    "            elif perspective[0] == 'S':\n",
    "                perspective = 'front'\n",
    "            else:\n",
    "                perspective = None;\n",
    "                print('Perspective error:', img_name)\n",
    "                \n",
    "            # Label\n",
    "            try:\n",
    "                label = labels_dict[img_name[4:6]]\n",
    "            except:\n",
    "                print('Label error:', img_name)\n",
    "        \n",
    "            # User ID\n",
    "            row_id = dir_name[1:]\n",
    "            if row_id in users:\n",
    "                user_id = users[row_id][0]['user_id']\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users[row_id] = []\n",
    "                id_counter += 1\n",
    "\n",
    "            users[row_id].append({\n",
    "                'dataset': dataset_name, \n",
    "                'user_id': user_id,\n",
    "                'name': img_name,\n",
    "                'class': label,\n",
    "                'age': None,\n",
    "                'gender': gender,\n",
    "                'race': 'swedish',\n",
    "                'perspective': perspective, \n",
    "                'age_group': '20-30',\n",
    "                'subset': None,\n",
    "                'auto_age': 0,\n",
    "                'auto_gender': 0,\n",
    "                'auto_perspective': 0,\n",
    "                'img_path': os.path.join(input_path, dir_name, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_imgs_user([row.pop('img_path') for row in user])\n",
    "        for row in user:\n",
    "            row['age'] = np.clip(age, 20, 30) if age is not None else None\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d0964",
   "metadata": {},
   "source": [
    "## JAFFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b526f-797e-4810-b9ef-467f0fd6933f",
   "metadata": {},
   "source": [
    "- race = japanese, according to article\n",
    "- age_group = young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5320831",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'JAFFE'\n",
    "input_path = 'C:/DATASETS/JAFFE'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'HA': 'happiness',\n",
    "    'SA': 'sadness',\n",
    "    'FE': 'fear',\n",
    "    'AN': 'anger',\n",
    "    'NE': 'neutral', \n",
    "    'SU': 'surprise', \n",
    "    'DI': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for img_name in os.listdir(os.path.join(input_path)):\n",
    "\n",
    "        # Label\n",
    "        try:\n",
    "            label = labels_dict[img_name[3:5]]\n",
    "        except:\n",
    "            print('Label error:', img_name)\n",
    "        \n",
    "        # User ID\n",
    "        row_id = img_name[:2]\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'name': img_name,\n",
    "            'class': label,\n",
    "            'age': None,\n",
    "            'gender': 'female',\n",
    "            'race': 'japanese',\n",
    "            'perspective': 'front', \n",
    "            'age_group': 'young',\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0,\n",
    "            'img_path': os.path.join(input_path, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_imgs_user([row.pop('img_path') for row in user])\n",
    "        for row in user:\n",
    "            row['age'] = age\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e2c59",
   "metadata": {},
   "source": [
    "## FEGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371eff5-4d87-4192-a360-586fd206c661",
   "metadata": {},
   "source": [
    "- race = caucasian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933c3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'FEGA'\n",
    "input_path = 'C:/DATASETS/FEGA'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'Allegria': 'happiness',\n",
    "    'Tristezza': 'sadness',\n",
    "    'Paura': 'fear',\n",
    "    'Arrabbiato': 'anger',\n",
    "    'Neutra': 'neutral', \n",
    "    'Sorpresa': 'surprise', \n",
    "    'Disgusto': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for img_name in os.listdir(os.path.join(input_path)):\n",
    "        img_name_split = img_name.split('_')\n",
    "\n",
    "        # Label\n",
    "        try:\n",
    "            label = labels_dict[img_name_split[4]]\n",
    "        except:\n",
    "            print('Label error:', img_name)\n",
    "                  \n",
    "        # Gender\n",
    "        gender = img_name_split[1]\n",
    "        if gender == 'F' or gender == 'f':\n",
    "            gender = 'female'\n",
    "        elif gender == 'M' or gender == 'm':\n",
    "            gender = 'male'\n",
    "        else:\n",
    "            gender = None\n",
    "            print('Gender error:', img_name)\n",
    "        \n",
    "        # User ID\n",
    "        row_id = img_name_split[1] + '_' + img_name_split[2] + '_' + img_name_split[3]\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'name': img_name,\n",
    "            'class': label,\n",
    "            'age': img_name_split[2],\n",
    "            'gender': gender,\n",
    "            'race': 'caucasian',\n",
    "            'perspective': 'front', \n",
    "            'age_group': None,\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0,\n",
    "            'img_path': os.path.join(input_path, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        for row in user:\n",
    "            row.pop('img_path')\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2237b5e",
   "metadata": {},
   "source": [
    "## LIFESPAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa9ab0",
   "metadata": {},
   "source": [
    "- 'Annoyed' and 'Grumpy' considered as anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc870f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'LIFESPAN'\n",
    "input_path = 'C:/DATASETS/LIFESPAN/Expressions'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "id_counter = 1\n",
    "users = {}\n",
    "labels_dict = {\n",
    "    'happy': 'happiness',\n",
    "    'sad': 'sadness',\n",
    "    'annoyed': 'anger',\n",
    "    'angry': 'anger',\n",
    "    'grumpy': 'anger',\n",
    "    'neutral': 'neutral', \n",
    "    'profile': 'neutral', \n",
    "    'surprised': 'surprise',\n",
    "    'disgusted': 'disgust'\n",
    "}\n",
    "\n",
    "prefixes = ['', 'EM' 'TSF', 'J', 'W', 'TM']\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "\n",
    "    for dir1 in os.listdir(os.path.join(input_path)):\n",
    "        for img_name in os.listdir(os.path.join(input_path, dir1)):\n",
    "\n",
    "            # Gender\n",
    "            gender = 'female' if 'female' in img_name else 'male'\n",
    "\n",
    "            race = img_name.split(gender)[0]\n",
    "            if race in [i+'W' for i in prefixes]:\n",
    "                race = 'white'\n",
    "            elif race in [i+'B' for i in prefixes]:\n",
    "                race = 'black'\n",
    "            elif race in [i+'A' for i in prefixes]:\n",
    "                race = 'asian'\n",
    "            elif race in [i+'I' for i in prefixes]:\n",
    "                race = 'indian'\n",
    "            elif race in [i+'H' for i in prefixes]:\n",
    "                race = 'hispanic'\n",
    "            else:\n",
    "                print(img_name)\n",
    "            \n",
    "            # Age\n",
    "            age = img_name.split(gender)[1][0:2]\n",
    "            if age[0] == '_':\n",
    "                age = img_name.split(gender)[1][1:3]\n",
    "\n",
    "            # Expression\n",
    "            expression = dir1.split()[0].lower()\n",
    "    \n",
    "            # User ID\n",
    "            # if expression in ['happy', 'neutral', 'profile']:\n",
    "            #     aux = img_name.split(expression)[0]\n",
    "            #     aux1 = race = img_name.split(gender)[0][-1]\n",
    "            #     row_id = aux1 + gender + aux.split(gender)[1]\n",
    "            # else:\n",
    "            row_id = img_name.split(expression)[0]\n",
    "            \n",
    "            if row_id in users:\n",
    "                user_id = users[row_id][0]['user_id']\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users[row_id] = []\n",
    "                id_counter += 1\n",
    "\n",
    "            users[row_id].append({\n",
    "                'dataset': dataset_name, \n",
    "                'user_id': user_id,\n",
    "                'name': img_name,\n",
    "                'class': labels_dict[expression],\n",
    "                'age': age,\n",
    "                'gender': gender,\n",
    "                'race': race,\n",
    "                'perspective': 'front' if expression != 'profile' else 'full_right', \n",
    "                'age_group': None,\n",
    "                'subset': None,\n",
    "                'auto_age': 0,\n",
    "                'auto_gender': 0,\n",
    "                'auto_perspective': 0,\n",
    "                'img_path': os.path.join(input_path, str(class_i), img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        for row in user:\n",
    "            row.pop('img_path')\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b0f3bf",
   "metadata": {},
   "source": [
    "## Google-FE-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7043ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Google-FE-Test'\n",
    "input_path = 'C:/DATASETS/Google-FE-Test'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels = ['anger','disgust','fear','happiness','neutral','sadness','surprise']\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for class_i, label in enumerate(labels):\n",
    "        for img_name in os.listdir(os.path.join(input_path, str(class_i))):            \n",
    "        \n",
    "            # User ID\n",
    "            row_id = id_counter\n",
    "            if row_id in users:\n",
    "                user_id = users[row_id][0]['user_id']\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users[row_id] = []\n",
    "                id_counter += 1\n",
    "\n",
    "            users[row_id].append({\n",
    "                'dataset': dataset_name, \n",
    "                'user_id': None,\n",
    "                'name': img_name,\n",
    "                'class': label,\n",
    "                'age': None,\n",
    "                'gender': None,\n",
    "                'race': None,\n",
    "                'perspective': 'front', \n",
    "                'age_group': None,\n",
    "                'subset': None,\n",
    "                'auto_age': 0,\n",
    "                'auto_gender': 0,\n",
    "                'auto_perspective': 0,\n",
    "                'img_path': os.path.join(input_path, str(class_i), img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, gender = get_age_gender_imgs_user([row.pop('img_path') for row in user], mode=2)\n",
    "        for row in user:\n",
    "            row['age'] = age\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            row['gender'] = gender\n",
    "            row['auto_gender'] = 1 if row['gender'] is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7615c06-72d1-4581-9874-ae0c08a0f619",
   "metadata": {},
   "source": [
    "## BU-4DFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b4286-e493-4f12-9098-dfcfeb1590fc",
   "metadata": {},
   "source": [
    "- Version with frames already sampled. Some images are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8664c62-c8b5-4c4f-a8d9-6172cbd42f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'BU-4DFE'\n",
    "input_path = 'C:/DATASETS/BU-4DFE'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'Happy': 'happiness',\n",
    "    'Sad': 'sadness',\n",
    "    'Fear': 'fear',\n",
    "    'Angry': 'anger',\n",
    "    'Neutral': 'neutral', \n",
    "    'Surprise': 'surprise', \n",
    "    'Disgust': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for img_name in os.listdir(os.path.join(input_path)):\n",
    "                  \n",
    "        # Gender\n",
    "        gender = img_name[0]\n",
    "        if gender == 'F' or gender == 'f':\n",
    "            gender = 'female'\n",
    "        elif gender == 'M' or gender == 'm':\n",
    "            gender = 'male'\n",
    "        else:\n",
    "            gender = None\n",
    "            print('Gender error:', img_name)\n",
    "\n",
    "        # Label\n",
    "        try:\n",
    "            label = labels_dict[img_name.split('_')[1]]\n",
    "        except:\n",
    "            print('Label error:', img_name)\n",
    "        \n",
    "        # User ID\n",
    "        row_id = img_name[:4]\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'name': img_name,\n",
    "            'class': label,\n",
    "            'age': None,\n",
    "            'gender': gender,\n",
    "            'race': None,\n",
    "            'perspective': 'front', \n",
    "            'age_group': '18-45',\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0,\n",
    "            'img_path': os.path.join(input_path, img_name)})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_imgs_user([row.pop('img_path') for row in user])\n",
    "        for row in user:\n",
    "            row['age'] = np.clip(age, 18, 45) if age is not None else None\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcacfe95-7113-4040-9ed9-39a94fe0d3e7",
   "metadata": {},
   "source": [
    "## CK+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85ba2d-0403-4d2c-8c71-f32ec3ea9d98",
   "metadata": {},
   "source": [
    "- Frame sampling applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f46e6-2e46-4a5f-87bf-cfaa08e8ada1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'CK+'\n",
    "input_path = 'C:/DATASETS/CK+'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    0: 'neutral', \n",
    "    1: 'anger',\n",
    "    2: 'contempt',\n",
    "    3: 'disgust',\n",
    "    4: 'fear',\n",
    "    5: 'happiness',\n",
    "    6: 'sadness',\n",
    "    7: 'surprise', \n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for dir_name1 in os.listdir(os.path.join(input_path, 'extended-cohn-kanade-images')):\n",
    "        for dir_name2 in os.listdir(os.path.join(input_path, 'extended-cohn-kanade-images', dir_name1)):\n",
    "\n",
    "            # Label\n",
    "            label_path = os.path.join(input_path, 'Emotion_labels', dir_name1, dir_name2)\n",
    "            if not os.path.exists(label_path):\n",
    "                print('No label:', label_path)\n",
    "                continue\n",
    "            else:\n",
    "                label_path_dirs = os.listdir(label_path)\n",
    "                if len(label_path_dirs) < 1:\n",
    "                    print('No label:', label_path)\n",
    "                    continue\n",
    "                else:\n",
    "                    with open(os.path.join(label_path, label_path_dirs[0]), 'r', newline='') as f:\n",
    "                        label = int(float(f.read()))\n",
    "            \n",
    "            # Use only first, middle and last images\n",
    "            imgs_list = os.listdir(os.path.join(input_path, 'extended-cohn-kanade-images', dir_name1, dir_name2))\n",
    "            for img_name, label in zip([imgs_list[0], imgs_list[len(imgs_list)//2], imgs_list[-1]], [0, label, label]):\n",
    "                \n",
    "                # User ID\n",
    "                row_id = dir_name1\n",
    "                if row_id in users:\n",
    "                    user_id = users[row_id][0]['user_id']\n",
    "                else:\n",
    "                    user_id = dataset_name + '-' + str(id_counter)\n",
    "                    users[row_id] = []\n",
    "                    id_counter += 1\n",
    "\n",
    "                users[row_id].append({\n",
    "                    'dataset': dataset_name, \n",
    "                    'user_id': user_id,\n",
    "                    'name': img_name,\n",
    "                    'class': labels_dict[label],\n",
    "                    'age': None,\n",
    "                    'gender': None,\n",
    "                    'race': None,\n",
    "                    'perspective': 'front', \n",
    "                    'age_group': None,\n",
    "                    'subset': None,\n",
    "                    'auto_age': 0,\n",
    "                    'auto_gender': 0,\n",
    "                    'auto_perspective': 0,\n",
    "                    'img_path': os.path.join(input_path, 'extended-cohn-kanade-images', dir_name1, dir_name2, img_name)})\n",
    "            \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, gender = get_age_gender_imgs_user([row['img_path'] for row in user])\n",
    "        for row in user:\n",
    "\n",
    "            img_path = row.pop('img_path')\n",
    "            perspective = pose_to_text(get_pose(cv2.imread(img_path), use_detector=True))\n",
    "\n",
    "            row['auto_age'] = 1 if row['age'] is None and age is not None else 0\n",
    "            row['age'] = age\n",
    "            row['auto_gender'] = 1 if row['gender'] is None and gender is not None else 0\n",
    "            row['gender'] = gender\n",
    "            row['auto_perspective'] = 1 if row['perspective'] is None and perspective is not None else 0\n",
    "            row['perspective'] = perspective\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7afd0-0926-4b43-bb6b-e98e605bf7be",
   "metadata": {},
   "source": [
    "## MMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ababc8b-90d9-4271-aa8b-7b0aa1f0c139",
   "metadata": {},
   "source": [
    "- Bad annotations for race: only two labels when there should be more, and there are errors. For example subjects 34, 39, 5, 53 and 54 are annotated with 1. Subject 50 should not be labelled with 0 either.\n",
    "- Frame sampling applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50401cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MMI'\n",
    "input_path = 'C:/DATASETS/MMI'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    1: 'anger',\n",
    "    2: 'disgust',\n",
    "    3: 'fear',\n",
    "    4: 'happiness', \n",
    "    5: 'sadness', \n",
    "    6: 'surprise',\n",
    "    7: 'scream',\n",
    "    8: 'boredom',\n",
    "    9: 'sleepy',\n",
    "}\n",
    "gender_dict = {\n",
    "    0: 'female',\n",
    "    1: 'male'\n",
    "}\n",
    "race_dict = {\n",
    "    0: 'white',\n",
    "    1: 'hispanic',\n",
    "    2: 'asian'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "\n",
    "    # Get subjects info\n",
    "    subjects_dict = {}\n",
    "    for subject_xml in os.listdir(os.path.join(input_path, 'Subjects')):\n",
    "        subject_xml_path = os.path.join(input_path, 'Subjects', subject_xml)\n",
    "        subject_xml_file = ET.parse(subject_xml_path).getroot()\n",
    "\n",
    "        id = int(subject_xml.split('subject')[-1].split('.')[0])\n",
    "        subjects_dict[id] = {\n",
    "            'id': id,\n",
    "            'age_of_birth': int(subject_xml_file.attrib['dob'].split('-')[0]),\n",
    "            'gender': gender_dict[int(subject_xml_file.attrib['gender'])],\n",
    "            'race': race_dict[int(subject_xml_file.attrib['ethnicity'])]\n",
    "        }\n",
    "\n",
    "    # Get session info\n",
    "    for session_num in os.listdir(os.path.join(input_path, 'Sessions')):\n",
    "\n",
    "        # Get xml file and video\n",
    "        aux = glob.glob(os.path.join(input_path, 'Sessions', session_num, '*.avi'))\n",
    "        if len(aux) == 0:\n",
    "            aux = glob.glob(os.path.join(input_path, 'Sessions', session_num, '*.jpg'))\n",
    "        if len(aux) == 0:\n",
    "            continue\n",
    "        video_path = aux[0]\n",
    "        xml_file = ET.parse(video_path[:-3]+'xml').getroot()\n",
    "        xml_session_file = ET.parse(os.path.join(input_path, 'Sessions', session_num, 'session.xml')).getroot()\n",
    "\n",
    "        # Label\n",
    "        aux = xml_file.find(\".//*[@Name='Emotion']\")\n",
    "        if aux is None:\n",
    "            continue\n",
    "        \n",
    "        label = int(aux.attrib['Value'])\n",
    "\n",
    "        # Case of no emotion label\n",
    "        if label not in labels_dict:\n",
    "            continue\n",
    "\n",
    "        label = labels_dict[label]\n",
    "        \n",
    "        # User ID\n",
    "        row_id = int(os.path.basename(video_path)[1:].split('-')[0])\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        info_subject = row_id in subjects_dict\n",
    "        \n",
    "        # Gender\n",
    "        gender = subjects_dict[row_id]['gender'] if info_subject else None\n",
    "\n",
    "        # Age\n",
    "        age = int(xml_session_file.attrib['recDate'].split('-')[0]) - subjects_dict[row_id]['age_of_birth'] if info_subject else None\n",
    "\n",
    "        # Perspective\n",
    "        perspective = int(xml_session_file.find('track').attrib['view'])\n",
    "\n",
    "        # Race\n",
    "        race = subjects_dict[row_id]['race'] if info_subject else None\n",
    "        race = None # Labels are not reliable, so we remove them\n",
    "\n",
    "        if video_path.endswith('.jpg'):\n",
    "            print(video_path)\n",
    "\n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'video_name': os.path.basename(video_path),\n",
    "            'class': label,\n",
    "            'age': age,\n",
    "            'gender': gender,\n",
    "            'race': race,\n",
    "            'perspective_type': perspective, \n",
    "            'age_group': None,\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0,\n",
    "            'video_path': video_path})\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        if user[0]['age'] is None or user[0]['gender'] is None:\n",
    "            age, gender = get_age_gender_videos_user(list(set([row['video_path'] for row in user])))\n",
    "        for row in user:\n",
    "            \n",
    "            if row['age'] is None:\n",
    "                row['age'] = age\n",
    "                row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            \n",
    "            if row['gender'] is None:\n",
    "                row['gender'] = gender\n",
    "                row['auto_gender'] = 1 if row['gender'] is not None else 0\n",
    "            \n",
    "            video_path = row.pop('video_path')\n",
    "            video_name = row.pop('video_name')\n",
    "            perspective_type = row.pop('perspective_type')\n",
    "            subject = int(video_name[1:].split('-')[0])\n",
    "            label = row['class']\n",
    "            \n",
    "            # Sample video\n",
    "            try:\n",
    "                frames = get_frames(video_path, skip=5, mode='part', first_frame=0, max_frame=-1)\n",
    "            except:\n",
    "                print('Error:', video_path)\n",
    "                continue\n",
    "\n",
    "            for frame_i, frame in enumerate(frames):\n",
    "\n",
    "                if frame_i not in [0, 2, 3]:\n",
    "                    continue\n",
    "\n",
    "                if frame_i == 0:\n",
    "                    row['class'] = 'neutral'\n",
    "                else:\n",
    "                    row['class'] = label\n",
    "\n",
    "                # Save as it is ignoring perspective field\n",
    "                if subject >= 53:\n",
    "\n",
    "                    frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "                    # cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame)\n",
    "                    row['name'] = frame_name\n",
    "                    row['perspective'] = 'front'\n",
    "                    spamwriter.writerow(row)\n",
    "\n",
    "                # Divide frames in 2\n",
    "                elif perspective_type == 2:\n",
    "\n",
    "                    if subject in [3, 5, 6, 15, 16]:\n",
    "\n",
    "                        # full_right\n",
    "                        frame_name = video_name.split('.')[0] + '_right_f' + str(frame_i+1) + '.png'\n",
    "                        # cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame[:, frame.shape[1]//2:,...])\n",
    "                        row['name'] = frame_name\n",
    "                        row['perspective'] = 'full_right'\n",
    "                        spamwriter.writerow(row)\n",
    "\n",
    "                        # front\n",
    "                        frame_name = video_name.split('.')[0] + '_front_f' + str(frame_i+1) + '.png'\n",
    "                        # cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame[:, :frame.shape[1]//2,...])\n",
    "                        row['name'] = frame_name\n",
    "                        row['perspective'] = 'front'\n",
    "                        spamwriter.writerow(row)\n",
    "                    \n",
    "                    else:\n",
    "\n",
    "                        # full_left\n",
    "                        frame_name = video_name.split('.')[0] + '_left_f' + str(frame_i+1) + '.png'\n",
    "                        # cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame[:, :frame.shape[1]//2,...])\n",
    "                        row['name'] = frame_name\n",
    "                        row['perspective'] = 'full_left'\n",
    "                        spamwriter.writerow(row)\n",
    "\n",
    "                        # front\n",
    "                        frame_name = video_name.split('.')[0] + '_front_f' + str(frame_i+1) + '.png'\n",
    "                        # cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame[:, frame.shape[1]//2:,...])\n",
    "                        row['name'] = frame_name\n",
    "                        row['perspective'] = 'front'\n",
    "                        spamwriter.writerow(row)\n",
    "                \n",
    "                # Rotate clockwise\n",
    "                elif perspective_type == 0:\n",
    "\n",
    "                    frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "                    # cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE))\n",
    "                    row['name'] = frame_name\n",
    "                    row['perspective'] = 'front'\n",
    "                    spamwriter.writerow(row)\n",
    "                \n",
    "                # Rotate counterclockwise\n",
    "                elif perspective_type == 1:\n",
    "\n",
    "                    frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "                    # cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "                    row['name'] = frame_name\n",
    "                    row['perspective'] = 'front' if subject != 21 else 'full_right'\n",
    "                    spamwriter.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e1f368",
   "metadata": {},
   "source": [
    "## BioVidEmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5d4b8",
   "metadata": {},
   "source": [
    "- Frame sampling applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf25fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'BioVidEmo'\n",
    "input_path = 'C:/DATASETS/BioVidEmo'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'anger': 'anger',\n",
    "    'disgust': 'disgust',\n",
    "    'fear': 'fear',\n",
    "    'amusement': 'happiness', \n",
    "    'sad': 'sadness',\n",
    "}\n",
    "gender_dict = {\n",
    "    'w': 'female',\n",
    "    'm': 'male'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "\n",
    "    # Get session info\n",
    "    for video_name in os.listdir(os.path.join(input_path, 'Videos')):\n",
    "\n",
    "        # Label\n",
    "        label = labels_dict[video_name.split('-')[-1].split('.')[0]]\n",
    "        \n",
    "        # User ID\n",
    "        row_id = video_name.split('-')[0]+video_name.split('-')[1]\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "        \n",
    "        # Gender\n",
    "        gender = gender_dict[video_name.split('_')[1]]\n",
    "\n",
    "        # Age\n",
    "        age = int(video_name.split('-')[1].split('_')[2])\n",
    "\n",
    "        users[row_id].append({\n",
    "            'dataset': dataset_name, \n",
    "            'user_id': user_id,\n",
    "            'video_name': video_name,\n",
    "            'class': label,\n",
    "            'age': age,\n",
    "            'gender': gender,\n",
    "            'race': None,\n",
    "            'perspective': None, \n",
    "            'age_group': None,\n",
    "            'subset': None,\n",
    "            'auto_age': 0,\n",
    "            'auto_gender': 0,\n",
    "            'auto_perspective': 0,\n",
    "            'video_path': os.path.join(input_path, 'Videos', video_name)})\n",
    "    \n",
    "    for user in tqdm(users.values()):\n",
    "        for row in user:\n",
    "            \n",
    "            video_path = row.pop('video_path')\n",
    "            video_name = row.pop('video_name')\n",
    "            \n",
    "            # Sample video\n",
    "            try:\n",
    "                frames = get_frames(video_path, skip=5, mode='auto', first_frame=0, max_frame=-1)\n",
    "            except:\n",
    "                print('Error:', video_path)\n",
    "                continue\n",
    "\n",
    "            for frame_i, frame in enumerate(frames):\n",
    "                    \n",
    "                frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "                cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame)\n",
    "                row['name'] = frame_name\n",
    "                \n",
    "                perspective = get_pose(frame, use_detector=True)\n",
    "                perspective = pose_to_text(perspective) if perspective is not None else None\n",
    "                row['auto_perspective'] = 1 if perspective is not None else 0\n",
    "                row['perspective'] = perspective\n",
    "                spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf1c087",
   "metadata": {},
   "source": [
    "## ElderReact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591be9e9-74f9-4e71-9fed-960e1bc54b82",
   "metadata": {},
   "source": [
    "- all_labels.txt obtained by merging train_labels.txt, dev_labels.txt and test_labels.txt. Header also added.\n",
    "- dev, train and test folders were merged into one\n",
    "- Multiple labels for the same video.\n",
    "- Users with wrong labels: same identifier used for multiple users (aprox. 20%)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855119c-d699-431d-9bd6-27920c28525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ElderReact'\n",
    "input_path = 'C:/DATASETS/ElderReact'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'Happiness': 'happiness',\n",
    "    'Sadness': 'sadness',\n",
    "    'Fear': 'fear',\n",
    "    'Anger': 'anger',\n",
    "    'Surprise': 'surprise', \n",
    "    'Disgust': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile, open(os.path.join(input_path, 'Annotations', 'all_labels.txt'), 'r') as csvfile_input:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    reader = csv.DictReader(csvfile_input, delimiter=' ')\n",
    "    for row in tqdm(reader):\n",
    "        \n",
    "        # File name, fixing some naming errors\n",
    "        video_name = row['filename']\n",
    "        if not os.path.exists(os.path.join(input_path, 'Videos', video_name)):\n",
    "            print('Not found:', video_name)\n",
    "                  \n",
    "        # Gender\n",
    "        gender = row['Gender']\n",
    "        if gender == 'F' or gender == 'f':\n",
    "            gender = 'female'\n",
    "        elif gender == 'M' or gender == 'm':\n",
    "            gender = 'male'\n",
    "        else:\n",
    "            gender = None\n",
    "            print('Gender error:', row)\n",
    "        \n",
    "        # User ID\n",
    "        row_id = row['filename'].split('_'+row['filename'].split('_')[-1])[0]\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        # Multiple labels:\n",
    "        some_label = False\n",
    "        for label in labels_dict.keys():\n",
    "            if row[label] == '1':\n",
    "                some_label = True\n",
    "                users[row_id].append({\n",
    "                    'dataset': dataset_name, \n",
    "                    'user_id': user_id,\n",
    "                    'video_name': video_name,\n",
    "                    'class': labels_dict[label],\n",
    "                    'age': None,\n",
    "                    'gender': gender,\n",
    "                    'race': None,\n",
    "                    'perspective': None, \n",
    "                    'age_group': 'elderly',\n",
    "                    'subset': row['subset'],\n",
    "                    'auto_age': 0,\n",
    "                    'auto_gender': 0,\n",
    "                    'auto_perspective': 0,\n",
    "                    'video_path': os.path.join(input_path, 'Videos', video_name)})\n",
    "        \n",
    "        # In case there are not any labels for the video\n",
    "        if not some_label and len(users[row_id]) == 0:\n",
    "            print('No label:', video_name)\n",
    "            id_counter -= 1\n",
    "            users.pop(row_id)\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, _ = get_age_gender_videos_user(list(set([row['video_path'] for row in user])))\n",
    "        for row in user:\n",
    "            row['age'] = age\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            \n",
    "            video_path = row.pop('video_path')\n",
    "            video_name = row.pop('video_name')\n",
    "            \n",
    "            # Sample video\n",
    "            frames = get_frames(video_path, skip=5, mode='auto', first_frame=0, max_frame=-1)\n",
    "            for frame_i, frame in enumerate(frames):\n",
    "\n",
    "                frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "\n",
    "                # Save frame\n",
    "                cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame)\n",
    "                row['name'] = frame_name\n",
    "                \n",
    "                perspective = get_pose(frame, use_detector=True)\n",
    "                perspective = pose_to_text(perspective) if perspective is not None else None\n",
    "                row['auto_perspective'] = 1 if perspective is not None else 0\n",
    "                row['perspective'] = perspective\n",
    "                spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9aa66",
   "metadata": {},
   "source": [
    "## LIRIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd4af06-c933-4ace-9324-662378ab04ad",
   "metadata": {},
   "source": [
    "- summaryParticipansts.xlsx converted to summaryParticipansts.csv\n",
    "- There are 17 videos with two labels\n",
    "- Naming errors: S8_suprise.mp4, S7_Happy_surprise.mp4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c903de-1743-4079-b3be-acad5677b1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'LIRIS'\n",
    "input_path = 'C:/DATASETS/LIRIS'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'Happy': 'happiness',\n",
    "    'happy': 'happiness',\n",
    "    'sad': 'sadness',\n",
    "    'fear': 'fear',\n",
    "    'anger': 'anger',\n",
    "    'surprise': 'surprise',\n",
    "    'suprise': 'surprise',\n",
    "    'disgust': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users_aux = {}\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile, open(os.path.join(input_path, 'summaryParticipansts.csv'), 'r') as csvfile_input:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "\n",
    "    # Get info of participants\n",
    "    reader = csv.DictReader(csvfile_input, delimiter=';')\n",
    "    for row in reader:\n",
    "        user_id = dataset_name + '-' + str(id_counter)\n",
    "        users_aux[row['Sr. No']] = {'id': user_id, 'sex': row['Sex'], 'age': row['Age']}\n",
    "        id_counter += 1\n",
    "\n",
    "    # Go through all videos\n",
    "    for video_name in tqdm(os.listdir(os.path.join(input_path, 'videos_208'))):\n",
    "        video_name_split = video_name.split('_')\n",
    "                  \n",
    "        # Gender\n",
    "        gender = users_aux[video_name_split[0]]['sex']\n",
    "        if gender == 'F' or gender == 'f':\n",
    "            gender = 'female'\n",
    "        elif gender == 'M' or gender == 'm':\n",
    "            gender = 'male'\n",
    "        else:\n",
    "            gender = None\n",
    "            print('Gender error:', row)\n",
    "            \n",
    "        # User ID\n",
    "        row_id = users_aux[video_name_split[0]]['id']\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        # Multiple labels:\n",
    "        some_label = False\n",
    "        for label in labels_dict.keys(): \n",
    "            if label in video_name:\n",
    "                some_label = True\n",
    "                users[row_id].append({\n",
    "                    'dataset': dataset_name, \n",
    "                    'user_id': user_id,\n",
    "                    'video_name': video_name,\n",
    "                    'class': labels_dict[label],\n",
    "                    'age': users_aux[video_name_split[0]]['age'],\n",
    "                    'gender': gender,\n",
    "                    'race': None,\n",
    "                    'perspective': None, \n",
    "                    'age_group': None,\n",
    "                    'subset': None,\n",
    "                    'auto_age': 0,\n",
    "                    'auto_gender': 0,\n",
    "                    'auto_perspective': 0,\n",
    "                    'video_path': os.path.join(input_path, 'videos_208', video_name)})\n",
    "        \n",
    "        # In case there are not any labels for the video\n",
    "        if not some_label and len(users[row_id]) == 0:\n",
    "            print('No label:', video_name)\n",
    "            id_counter -= 1\n",
    "            users.pop(row_id)\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        for row in user:\n",
    "            \n",
    "            video_path = row.pop('video_path')\n",
    "            video_name = row.pop('video_name')\n",
    "            \n",
    "            # Sample video\n",
    "            frames = get_frames(video_path, skip=5, mode='auto', first_frame=0)\n",
    "            label_aux = row['class']\n",
    "            for frame_i, frame in enumerate(frames):\n",
    "                \n",
    "                if frame_i == 0:\n",
    "                    row['class'] = 'neutral'\n",
    "                else:\n",
    "                    row['class'] = label_aux\n",
    "\n",
    "                frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "\n",
    "                # Save frame\n",
    "                cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame)\n",
    "                row['name'] = frame_name\n",
    "                \n",
    "                perspective = get_pose(frame, use_detector=True)\n",
    "                perspective = pose_to_text(perspective) if perspective is not None else None\n",
    "                row['auto_perspective'] = 1 if perspective is not None else 0\n",
    "                row['perspective'] = perspective\n",
    "                spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41176cf4",
   "metadata": {},
   "source": [
    "## EMOREACT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650845ab-fca0-4733-a1e2-7502532e70ce",
   "metadata": {},
   "source": [
    "- labels and names from all subsets merged into all_labels.text and all_names.txt\n",
    "- videos merged into one folder\n",
    "- there are videos with more than one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44070a5-28fb-452d-82ba-790be2ab1376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'EMOREACT'\n",
    "input_path = 'C:/DATASETS/EMOREACT'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'Happiness': 'happiness',\n",
    "    'Fear': 'fear',\n",
    "    'Surprise': 'surprise', \n",
    "    'Disgust': 'disgust',\n",
    "    'Curiosity': 'curiosity',\n",
    "    'Uncertainty': 'uncertainty',\n",
    "    'Excitement': 'excitement',\n",
    "    'Frustration': 'frustration',\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile, open(os.path.join(input_path, 'Labels', 'all_labels.text'), 'r') as csv_input:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    reader = csv.DictReader(csv_input, delimiter=',', quotechar='\"')\n",
    "    for row in tqdm(reader):\n",
    "                    \n",
    "        # File name\n",
    "        video_name = row['Name']\n",
    "        \n",
    "        # User ID\n",
    "        row_id = id_counter\n",
    "        if row_id in users:\n",
    "            user_id = users[row_id][0]['user_id']\n",
    "        else:\n",
    "            user_id = dataset_name + '-' + str(id_counter)\n",
    "            users[row_id] = []\n",
    "            id_counter += 1\n",
    "\n",
    "        # Multiple labels:\n",
    "        some_label = False\n",
    "        for label in labels_dict.keys(): \n",
    "            if row[label] == '1':\n",
    "                some_label = True\n",
    "                users[row_id].append({\n",
    "                    'dataset': dataset_name, \n",
    "                    'user_id': None, # user_id,\n",
    "                    'video_name': video_name,\n",
    "                    'class': labels_dict[label],\n",
    "                    'age': None,\n",
    "                    'gender': None,\n",
    "                    'race': None,\n",
    "                    'perspective': None, \n",
    "                    'age_group': '4-14',\n",
    "                    'subset': row['Subset'],\n",
    "                    'auto_age': 0,\n",
    "                    'auto_gender': 0,\n",
    "                    'auto_perspective': 0,\n",
    "                    'video_path': os.path.join(input_path, 'Data', video_name)})\n",
    "        \n",
    "        # In case there are not any labels for the video\n",
    "        if not some_label and len(users[row_id]) == 0:\n",
    "            print('No label:', video_name)\n",
    "            id_counter -= 1\n",
    "            users.pop(row_id)\n",
    "    \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        age, gender = get_age_gender_videos_user(list(set([row['video_path'] for row in user])))\n",
    "        for row in user:\n",
    "            row['age'] = np.clip(age, 4, 14) if age is not None else None\n",
    "            row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            row['gender'] = gender\n",
    "            row['auto_gender'] = 1 if row['gender'] is not None else 0\n",
    "            \n",
    "            video_path = row.pop('video_path')\n",
    "            video_name = row.pop('video_name')\n",
    "            \n",
    "            # Sample video\n",
    "            frames = get_frames(video_path, skip=5, mode='auto', first_frame=0, max_frame=-1)\n",
    "            for frame_i, frame in enumerate(frames):\n",
    "\n",
    "                frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "\n",
    "                # Save frame\n",
    "                cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame)\n",
    "                row['name'] = frame_name\n",
    "                \n",
    "                perspective = get_pose(frame, use_detector=True)\n",
    "                perspective = pose_to_text(perspective) if perspective is not None else None\n",
    "                row['auto_perspective'] = 1 if perspective is not None else 0\n",
    "                row['perspective'] = perspective\n",
    "                spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e4a34",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SFEW/AFEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d755b3d9-929e-4f90-9f7e-d1dec0f4100a",
   "metadata": {},
   "source": [
    "- Test subset not used because it is not labeled!\n",
    "- Actors' age used.\n",
    "- Errors in Train_6.xml: video 00:37:01,120 has age and name inverted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee731822-0065-4ec8-b4de-d994d5b8386f",
   "metadata": {},
   "source": [
    "### AFEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6571f-c594-47a0-9e30-3c3cec41d372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'AFEW'\n",
    "input_path = 'C:/DATASETS/AFEW-SFEW/AFEW'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'Happy': 'happiness',\n",
    "    'Sad': 'sadness',\n",
    "    'Fear': 'fear',\n",
    "    'Angry': 'anger',\n",
    "    'Neutral': 'neutral', \n",
    "    'Surprise': 'surprise', \n",
    "    'Disgust': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users = {}\n",
    "users_aux = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "\n",
    "    # For Train and Val subsets\n",
    "    for subset in ['Train', 'Val']:\n",
    "\n",
    "        xml_file = ET.parse(os.path.join(input_path, 'Labels', subset+'_6.xml')).getroot()\n",
    "\n",
    "        # Create xml dict\n",
    "        dict_movie = {}\n",
    "        for xml_movie in xml_file:\n",
    "\n",
    "            n_temp = xml_movie[0].text\n",
    "            video_name = n_temp[:2] + n_temp[3:5] + n_temp[6:8] + n_temp[9:12] + '.avi'\n",
    "            \n",
    "            # User ID\n",
    "            temp_id = xml_movie[2].attrib['NameOfActor']\n",
    "            if temp_id in users_aux:\n",
    "                user_id = users_aux[temp_id]\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users_aux[temp_id] = user_id\n",
    "                id_counter += 1\n",
    "\n",
    "            # Gender\n",
    "            gender = xml_movie[2].attrib['Gender'].lower()\n",
    "            if gender != 'female' and gender != 'male':\n",
    "                print('Gender error:', video_name)\n",
    "            \n",
    "            # Perspective\n",
    "            perspective = xml_movie[2].attrib['Pose']\n",
    "            if perspective == \"Frontal\":\n",
    "                perspective = 'front'\n",
    "\n",
    "            dict_movie[video_name] = {\n",
    "                'user_id': user_id,\n",
    "                'gender': gender,\n",
    "                'age': xml_movie[2].attrib['AgeOfActor'],\n",
    "                'perspective': perspective\n",
    "            }\n",
    "        \n",
    "        # Go through all labels\n",
    "        for label in os.listdir(os.path.join(input_path, 'Videos', subset+'_AFEW')):\n",
    "\n",
    "            # Go through all videos\n",
    "            for video_name in os.listdir(os.path.join(input_path, 'Videos', subset+'_AFEW', label)):\n",
    "                \n",
    "                if dict_movie[video_name]['user_id'] not in users:\n",
    "                    users[dict_movie[video_name]['user_id']] = []\n",
    "\n",
    "                users[dict_movie[video_name]['user_id']].append({\n",
    "                    'dataset': dataset_name, \n",
    "                    'user_id': dict_movie[video_name]['user_id'],\n",
    "                    'video_name': video_name,\n",
    "                    'class': labels_dict[label],\n",
    "                    'age': None if dict_movie[video_name]['age'] is None or dict_movie[video_name]['age'] == '' else dict_movie[video_name]['age'],\n",
    "                    'gender': None if dict_movie[video_name]['gender'] is None or dict_movie[video_name]['gender'] == '' else dict_movie[video_name]['gender'],\n",
    "                    'race': None,\n",
    "                    'perspective': None, #dict_movie[video_name]['perspective'],\n",
    "                    'age_group': None,\n",
    "                    'subset': subset.lower(),\n",
    "                    'auto_age': 0,\n",
    "                    'auto_gender': 0,\n",
    "                    'video_path': os.path.join(input_path, 'Videos', subset+'_AFEW', label, video_name)})\n",
    "                     \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        if user[0]['age'] is None or user[0]['gender'] is None:\n",
    "            age, gender = get_age_gender_videos_user(list(set([row['video_path'] for row in user])), reader='opencv')\n",
    "        for row in user:\n",
    "            \n",
    "            # Age\n",
    "            if row['age'] is None:\n",
    "                row['age'] = age\n",
    "                row['auto_age'] = 1 if row['age'] is not None else 0\n",
    "            \n",
    "            # Gender\n",
    "            if row['gender'] is None:\n",
    "                row['gender'] = gender\n",
    "                row['auto_gender'] = 1 if row['gender'] is not None else 0\n",
    "            \n",
    "            video_path = row.pop('video_path')\n",
    "            video_name = row.pop('video_name')\n",
    "            \n",
    "            # Sample video\n",
    "            frames = get_frames_opencv(video_path, skip=5, mode='auto', first_frame=0)\n",
    "            for frame_i, frame in enumerate(frames):\n",
    "\n",
    "                frame_name = video_name.split('.')[0] + '_f' + str(frame_i+1) + '.png'\n",
    "\n",
    "                # Save frame\n",
    "                cv2.imwrite(os.path.join(input_path, 'Frames', frame_name), frame)\n",
    "                row['name'] = frame_name\n",
    "\n",
    "                perspective = get_pose(frame, use_detector=True)\n",
    "                perspective = pose_to_text(perspective) if perspective is not None else None\n",
    "                row['auto_perspective'] = 1 if perspective is not None else 0\n",
    "                row['perspective'] = perspective\n",
    "                spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372548d-afeb-4d66-81bd-fef90e76b59c",
   "metadata": {},
   "source": [
    "### SFEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9346420-4ed1-4776-bec8-d7ebaf26f468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'SFEW'\n",
    "input_path = 'C:/DATASETS/AFEW-SFEW/SFEW'\n",
    "xml_input_path =  'C:/DATASETS/AFEW-SFEW/AFEW'\n",
    "output_path = os.path.join(output_labels_path, 'labels_' + dataset_name + '.csv')\n",
    "labels_dict = {\n",
    "    'Happy': 'happiness',\n",
    "    'Sad': 'sadness',\n",
    "    'Fear': 'fear',\n",
    "    'Angry': 'anger',\n",
    "    'Neutral': 'neutral', \n",
    "    'Surprise': 'surprise', \n",
    "    'Disgust': 'disgust'\n",
    "}\n",
    "id_counter = 1\n",
    "users_aux = {}\n",
    "users = {}\n",
    "\n",
    "with open(output_path, 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "\n",
    "    # For Train and Val subsets\n",
    "    for subset in ['Train', 'Val']:\n",
    "\n",
    "        xml_file = ET.parse(os.path.join(xml_input_path, 'Labels', subset+'_6.xml')).getroot()\n",
    "\n",
    "        # Create xml dict\n",
    "        dict_movie = {}\n",
    "        for xml_movie in xml_file:\n",
    "\n",
    "            n_temp = xml_movie[0].text\n",
    "            video_name = xml_movie.attrib['MovieTitle'] + '_' + n_temp[:2] + n_temp[3:5] + n_temp[6:8] + n_temp[9:12]\n",
    "            \n",
    "            # User ID\n",
    "            temp_id = xml_movie[2].attrib['NameOfActor']\n",
    "            if temp_id in users_aux:\n",
    "                user_id = users_aux[temp_id]\n",
    "            else:\n",
    "                user_id = dataset_name + '-' + str(id_counter)\n",
    "                users_aux[temp_id] = user_id\n",
    "                id_counter += 1\n",
    "\n",
    "            # Gender\n",
    "            gender = xml_movie[2].attrib['Gender'].lower()\n",
    "            if gender != 'female' and gender != 'male':\n",
    "                print('Gender error:', video_name)\n",
    "            \n",
    "            # Perspective\n",
    "            perspective = xml_movie[2].attrib['Pose']\n",
    "            if perspective == \"Frontal\":\n",
    "                perspective = 'front'\n",
    "\n",
    "            dict_movie[video_name] = {\n",
    "                'user_id': user_id,\n",
    "                'gender': gender,\n",
    "                'age': xml_movie[2].attrib['AgeOfActor'],\n",
    "                'perspective': perspective\n",
    "            }\n",
    "        \n",
    "        # Go through all labels\n",
    "        for label in os.listdir(os.path.join(input_path, subset)):\n",
    "\n",
    "            # Go through all images\n",
    "            for img_name in os.listdir(os.path.join(input_path, subset, label, label)):\n",
    "\n",
    "                try:\n",
    "                    img_split = img_name.split('_')\n",
    "                    video_name = img_split[0]\n",
    "                    for i in range(1, len(img_split)-1):\n",
    "                        video_name += '_' + img_split[i]\n",
    "                except:\n",
    "                    video_name = None\n",
    "                    print('Error parsing image:', img_name)\n",
    "\n",
    "                if video_name in dict_movie:\n",
    "                    \n",
    "                    row_id = dict_movie[video_name]['user_id']\n",
    "                    if row_id not in users:\n",
    "                        users[row_id] = []\n",
    "                    users[row_id].append({\n",
    "                        'dataset': dataset_name, \n",
    "                        'user_id': dict_movie[video_name]['user_id'],\n",
    "                        'name': img_name,\n",
    "                        'class': labels_dict[label],\n",
    "                        'age': dict_movie[video_name]['age'],\n",
    "                        'gender': dict_movie[video_name]['gender'],\n",
    "                        'race': None,\n",
    "                        'perspective': dict_movie[video_name]['perspective'],\n",
    "                        'age_group': None,\n",
    "                        'subset': subset.lower(),\n",
    "                        'auto_age': 0,\n",
    "                        'auto_gender': 0,\n",
    "                        'auto_perspective': 0,\n",
    "                        'img_path': os.path.join(input_path, subset, label, label, img_name)})\n",
    "                else:\n",
    "                    if video_name is not None:\n",
    "                        print('Video not found in xml:', video_name)\n",
    "                    \n",
    "                    user_id = dataset_name + '-' + str(id_counter)\n",
    "                    id_counter += 1\n",
    "                    users[user_id] = [{\n",
    "                        'dataset': dataset_name, \n",
    "                        'user_id': None,\n",
    "                        'name': img_name,\n",
    "                        'class': labels_dict[label],\n",
    "                        'age': None,\n",
    "                        'gender': None,\n",
    "                        'race': None,\n",
    "                        'perspective': None,\n",
    "                        'age_group': None,\n",
    "                        'subset': subset.lower(),\n",
    "                        'auto_age': 0,\n",
    "                        'auto_gender': 0,\n",
    "                        'auto_perspective': 0,\n",
    "                        'img_path': os.path.join(input_path, subset, label, label, img_name)}]\n",
    "        \n",
    "    # Add computed age and gender for the images of a user\n",
    "    for user in tqdm(users.values()):\n",
    "        if user[0]['age'] is None or user[0]['gender'] is None:\n",
    "            age, gender = get_age_gender_imgs_user([row['img_path'] for row in user])\n",
    "        else:\n",
    "            age = None\n",
    "            gender = None\n",
    "        for row in user:\n",
    "            img_path = row.pop('img_path')\n",
    "\n",
    "            if user[0]['perspective'] is None or user[0]['perspective'] == 'Non-Frontal':\n",
    "                perspective = get_pose(cv2.imread(img_path), use_detector=True)\n",
    "                perspective = pose_to_text(perspective) if perspective is not None else None\n",
    "                \n",
    "            row['age'] = age if row['age'] is None else row['age']\n",
    "            row['auto_age'] = 1 if age is not None else 0\n",
    "\n",
    "            row['gender'] = gender if row['gender'] is None else row['gender']\n",
    "            row['auto_gender'] = 1 if gender is not None else 0\n",
    "            \n",
    "            row['auto_perspective'] = 1 if (row['perspective'] is None or row['perspective'] == 'Non-Frontal') and perspective is not None else 0\n",
    "            row['perspective'] = perspective\n",
    "            \n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16764114",
   "metadata": {},
   "source": [
    "# UNIFIED DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad07351",
   "metadata": {},
   "source": [
    "## Merge dataset labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = ['AFEW']\n",
    "\n",
    "with open(os.path.join(output_root, 'labels.csv'), 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.DictWriter(csvfile, fieldnames=csv_columns, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writeheader()\n",
    "    \n",
    "    for csv_file_name in os.listdir(output_labels_path):\n",
    "        \n",
    "        # Skip datasets\n",
    "        csv_dname = csv_file_name.split('_')[1].split('.')[0]\n",
    "        if csv_dname in skip:\n",
    "            continue\n",
    "        \n",
    "        with open(os.path.join(output_labels_path, csv_file_name), 'r', newline='') as csvfile_input: \n",
    "            reader = csv.DictReader(csvfile_input, delimiter=',', quotechar='\"')\n",
    "            for row in reader:\n",
    "                spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f348dc4c-f2a2-44f4-be5c-ded3ccb2cf52",
   "metadata": {},
   "source": [
    "## Copy all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14077001-ec55-4696-ae3a-5ce4f2c00b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_imgs_path):\n",
    "    os.makedirs(output_imgs_path)\n",
    "\n",
    "# AffectNet\n",
    "dataset_name = 'AffectNet'\n",
    "input_path = 'C:/DATASETS/AffectNetUniques'\n",
    "labels = ['neutral','happiness','sadness','surprise','fear','disgust','anger','contempt']\n",
    "print(dataset_name)\n",
    "for class_i, label in tqdm(enumerate(labels)):\n",
    "    for img_name in os.listdir(os.path.join(input_path, str(class_i))):\n",
    "        shutil.copy(os.path.join(input_path, str(class_i), img_name), output_imgs_path)\n",
    "\n",
    "# DDCF\n",
    "dataset_name = 'DDCF'\n",
    "input_path = 'C:/DATASETS/DDCF'\n",
    "labels_in =  ['Afraid','Angry','Disgusted','Happy','Neutral','Pleased','Sad','Surprised']\n",
    "print(dataset_name)\n",
    "for class_i, label in tqdm(enumerate(labels_in)):\n",
    "    for dir_name in os.listdir(os.path.join(input_path, label)):\n",
    "        for img_name in os.listdir(os.path.join(input_path, label, dir_name)):\n",
    "            shutil.copy(os.path.join(input_path, label, dir_name, img_name), output_imgs_path)\n",
    "\n",
    "# DEFSS\n",
    "dataset_name = 'DEFSS'\n",
    "input_path = 'C:/DATASETS/DEFSS/Images'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# FACES\n",
    "dataset_name = 'FACES'\n",
    "input_path = 'C:/DATASETS/FACES/FACES'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# NIMH-ChEFS\n",
    "dataset_name = 'NIMH-ChEFS'\n",
    "input_path = 'C:/DATASETS/NIMH-ChEFS'\n",
    "print(dataset_name)\n",
    "for dir_name in tqdm(os.listdir(os.path.join(input_path))):\n",
    "    for img_name in os.listdir(os.path.join(input_path, dir_name)):\n",
    "        shutil.copy(os.path.join(input_path, dir_name, img_name), output_imgs_path)\n",
    "\n",
    "# RaFD\n",
    "dataset_name = 'RaFD'\n",
    "input_path = 'C:/DATASETS/RaFD'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# FER2013\n",
    "dataset_name = 'FER2013'\n",
    "input_path = 'C:/DATASETS/FER2013'\n",
    "labels_in =  ['Sad', 'Neutral', 'Angry', 'Disgust','Surprise','Fear', 'Happy']\n",
    "print(dataset_name)\n",
    "for label in tqdm(labels_in):\n",
    "    for img_name in os.listdir(os.path.join(input_path, label)):\n",
    "        shutil.copy(os.path.join(input_path, label, img_name), output_imgs_path)\n",
    "\n",
    "# ExpW\n",
    "dataset_name = 'ExpW'\n",
    "input_path = 'C:/DATASETS/ExpW/cropped'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# RAF-DB\n",
    "dataset_name = 'RAF-DB'\n",
    "input_path = 'C:/DATASETS/RAF-DB/DATASET'\n",
    "labels_in =  ['5', '7', '6', '3', '1', '2', '4']\n",
    "print(dataset_name)\n",
    "for split in ['train', 'test']:\n",
    "    for label in tqdm(labels_in):\n",
    "        for img_name in os.listdir(os.path.join(input_path, split, label)):\n",
    "            shutil.copy(os.path.join(input_path, split, label, img_name), output_imgs_path)\n",
    "\n",
    "# NHFI\n",
    "dataset_name = 'NHFI'\n",
    "input_path = 'C:/DATASETS/NHFI'\n",
    "labels_in = ['sadness', 'neutrality', 'anger', 'disgust','surprise','fear', 'happiness', 'contempt']\n",
    "print(dataset_name)\n",
    "for label in tqdm(labels_in):\n",
    "    for img_name in os.listdir(os.path.join(input_path, label)):\n",
    "        shutil.copy(os.path.join(input_path, label, img_name), os.path.join(output_imgs_path, label + '_' + img_name)) # Modified destiny name to avoid repeated names\n",
    "\n",
    "# WSEFEP\n",
    "dataset_name = 'WSEFEP'\n",
    "input_path = 'C:/DATASETS/WSEFEP/images'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# KDEF\n",
    "dataset_name = 'KDEF'\n",
    "input_path = 'C:/DATASETS/KDEF/images'\n",
    "print(dataset_name)\n",
    "for dir_name in tqdm(os.listdir(os.path.join(input_path))):\n",
    "    for img_name in os.listdir(os.path.join(input_path, dir_name)):\n",
    "        shutil.copy(os.path.join(input_path, dir_name, img_name), output_imgs_path)\n",
    "\n",
    "# JAFFE\n",
    "dataset_name = 'JAFFE'\n",
    "input_path = 'C:/DATASETS/JAFFE'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# FEGA\n",
    "dataset_name = 'FEGA'\n",
    "input_path = 'C:/DATASETS/FEGA'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# LIFESPAN\n",
    "dataset_name = 'LIFESPAN'\n",
    "input_path = 'C:/DATASETS/LIFESPAN/Expressions'\n",
    "print(dataset_name)\n",
    "for dir1 in os.listdir(os.path.join(input_path)):\n",
    "    for img_name in os.listdir(os.path.join(input_path, dir1)):\n",
    "        shutil.copy(os.path.join(input_path, dir1, img_name), output_imgs_path)\n",
    "\n",
    "# Google-FE-Test\n",
    "dataset_name = 'Google-FE-Test'\n",
    "input_path = 'C:/DATASETS/Google-FE-Test'\n",
    "labels = ['anger','disgust','fear','happiness','neutral','sadness','surprise']\n",
    "print(dataset_name)\n",
    "for class_i, label in enumerate(labels):\n",
    "    for img_name in os.listdir(os.path.join(input_path, str(class_i))):\n",
    "        shutil.copy(os.path.join(input_path, str(class_i), img_name), output_imgs_path)\n",
    "\n",
    "# BU-4DFE\n",
    "dataset_name = 'BU-4DFE'\n",
    "input_path = 'C:/DATASETS/BU-4DFE'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# CK+\n",
    "dataset_name = 'CK+'\n",
    "input_path = 'C:/DATASETS/CK+'\n",
    "print(dataset_name)\n",
    "for dir_name1 in os.listdir(os.path.join(input_path, 'extended-cohn-kanade-images')):\n",
    "    for dir_name2 in os.listdir(os.path.join(input_path, 'extended-cohn-kanade-images', dir_name1)):\n",
    "        for img_name in os.listdir(os.path.join(input_path, 'extended-cohn-kanade-images', dir_name1, dir_name2)):\n",
    "            shutil.copy(os.path.join(input_path, 'extended-cohn-kanade-images', dir_name1, dir_name2, img_name), output_imgs_path)\n",
    "\n",
    "# MMI\n",
    "dataset_name = 'MMI'\n",
    "input_path = 'C:/DATASETS/MMI/Frames'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# BioVidEmo\n",
    "dataset_name = 'BioVidEmo'\n",
    "input_path = 'C:/DATASETS/BioVidEmo/Frames'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# ElderReact\n",
    "dataset_name = 'ElderReact'\n",
    "input_path = 'C:/DATASETS/ElderReact/Frames'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# LIRIS\n",
    "dataset_name = 'LIRIS'\n",
    "input_path = 'C:/DATASETS/LIRIS/Frames'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# EMOREACT\n",
    "dataset_name = 'EMOREACT'\n",
    "input_path = 'C:/DATASETS/EMOREACT/Frames'\n",
    "print(dataset_name)\n",
    "for img_name in tqdm(os.listdir(input_path)):\n",
    "    shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "\n",
    "# AFEW/SFEW\n",
    "choice = 'SFEW'\n",
    "\n",
    "if choice == 'AFEW':\n",
    "    dataset_name = 'AFEW'\n",
    "    input_path = 'C:/DATASETS/AFEW-SFEW/AFEW/Frames'\n",
    "    print(dataset_name)\n",
    "    for img_name in tqdm(os.listdir(input_path)):\n",
    "        shutil.copy(os.path.join(input_path, img_name), output_imgs_path)\n",
    "elif choice == 'SFEW':\n",
    "    dataset_name = 'SFEW'\n",
    "    input_path = 'C:/DATASETS/AFEW-SFEW/SFEW'\n",
    "    print(dataset_name)\n",
    "    for subset in ['Train', 'Val']:\n",
    "        for label in os.listdir(os.path.join(input_path, subset)):\n",
    "            for img_name in tqdm(os.listdir(os.path.join(input_path, subset, label, label))):\n",
    "                shutil.copy(os.path.join(input_path, subset, label, label, img_name), output_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44280f3",
   "metadata": {},
   "source": [
    "## Check all images of a CSV file exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a345fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_csv_file = os.path.join(output_root, 'labels.csv')\n",
    "target_imgs_folder = output_imgs_path\n",
    "\n",
    "with open(target_csv_file, 'r', newline='') as csvfile_input: \n",
    "    reader = csv.DictReader(csvfile_input, delimiter=',', quotechar='\"')\n",
    "    for row in tqdm(reader):\n",
    "        if not os.path.exists(os.path.join(target_imgs_folder, row['name'])):\n",
    "            print('Image:', row['name'], 'does no exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f026c7",
   "metadata": {},
   "source": [
    "## Check all images in directory are in target CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cefb94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_csv_file = os.path.join(output_root, 'labels.csv')\n",
    "target_imgs_folder = output_imgs_path\n",
    "action = 'list' # 'remove'\n",
    "counter = 0\n",
    "\n",
    "with open(target_csv_file, 'r', newline='') as csvfile_input: \n",
    "    reader = csv.DictReader(csvfile_input, delimiter=',', quotechar='\"')\n",
    "    \n",
    "    # Set to store all names\n",
    "    names = set()\n",
    "    for row in tqdm(reader):\n",
    "        names.add(row['name'])\n",
    "    \n",
    "    # Check each image\n",
    "    for img_name in tqdm(os.listdir(target_imgs_folder)):\n",
    "        if img_name not in names:\n",
    "            counter += 1\n",
    "            if action == 'remove':\n",
    "                os.remove(os.path.join(target_imgs_folder, img_name))\n",
    "                print('Image:', img_name, 'does no exist in CSV file. DELETED')\n",
    "            else:\n",
    "                print('Image:', img_name, 'does no exist in CSV file!')\n",
    "\n",
    "if action == 'remove':\n",
    "    print('Total images removed:', counter)\n",
    "else:\n",
    "    print('Total images not in CSV:', counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447b9a0",
   "metadata": {},
   "source": [
    "# Fix some fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae33000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map age_group values to age_group_clean\n",
    "def map_age_group(age_group):\n",
    "    if age_group in ['kid', '10-17', '4-14']:\n",
    "        return 'child'\n",
    "    elif age_group in ['young', 'middle-age', '18-45', '20-30']:\n",
    "        return 'middle-age'\n",
    "    elif age_group == 'elderly':\n",
    "        return 'elder'\n",
    "    else:\n",
    "        return None  # Handle NaN values\n",
    "\n",
    "# Define a function to map age values to age_group_clean\n",
    "def map_age_to_clean(age):\n",
    "    if pd.isna(age):\n",
    "        return None\n",
    "    elif 0 <= age <= 17:\n",
    "        return 'child'\n",
    "    elif 18 <= age <= 59:\n",
    "        return 'middle-age'\n",
    "    elif age >= 60:\n",
    "        return 'elder'\n",
    "\n",
    "# Define a function to map age_group values to age_group_clean\n",
    "def map_gaze(perspective):\n",
    "    if perspective is None:\n",
    "        return None\n",
    "    if 'gaze_left' in perspective:\n",
    "        return 'left'\n",
    "    elif 'gaze_right' in perspective:\n",
    "        return 'right'\n",
    "    elif 'averted_gaze' in perspective:\n",
    "        return 'averted'\n",
    "    else:\n",
    "        return 'front'\n",
    "\n",
    "# Define a function to map age values to perspective\n",
    "def map_perspective(perspective):\n",
    "    if perspective is None:\n",
    "        return None\n",
    "    elif perspective == 'Non-Frontal':\n",
    "        return 'non-frontal'\n",
    "    elif perspective == 'averted_gaze':\n",
    "        return 'front'\n",
    "    elif 'gaze_left' in perspective:\n",
    "        return perspective.split('_gaze_left')[0]\n",
    "    elif 'gaze_right' in perspective:\n",
    "        return perspective.split('_gaze_right')[0]\n",
    "    else:\n",
    "        return perspective\n",
    "\n",
    "# Define a function to map race values\n",
    "def map_race(race):\n",
    "    if race == 'caucasian':\n",
    "        return 'caucasian'\n",
    "    elif race == 'black':\n",
    "        return 'black'\n",
    "    elif race == 'asian':\n",
    "        return 'asian'\n",
    "    elif race == 'indian':\n",
    "        return 'desi'\n",
    "    elif race == 'hispanic':\n",
    "        return 'hispanic'\n",
    "    elif race == 'arab':\n",
    "        return 'arab'\n",
    "    elif race == 'white':\n",
    "        return 'caucasian'\n",
    "    elif race == 'polish':\n",
    "        return 'caucasian'\n",
    "    elif race == 'swedish':\n",
    "        return 'caucasian'\n",
    "    elif race == 'moroccan':\n",
    "        return 'arab'\n",
    "    elif race == 'japanese':\n",
    "        return 'asian'\n",
    "    else:\n",
    "        print(race)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf054ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'dataset': 'category',\n",
    "    'user_id': 'category',\n",
    "    'name': str,\n",
    "    'class': 'category',\n",
    "    'age': 'Int8',\n",
    "    'gender':'category' ,\n",
    "    'race': 'category',\n",
    "    'perspective': 'category',\n",
    "    'age_group': 'category',\n",
    "    'subset': 'category',\n",
    "    'auto_age': bool,\n",
    "    'auto_gender': bool,\n",
    "    'auto_perspective': bool}\n",
    "df = pd.read_csv(csv_file_in, dtype=dtypes, sep=',', quotechar='\"')\n",
    "\n",
    "# Apply the mapping function to create the 'age_group_clean' column\n",
    "df['age_group_clean'] = df['age_group'].apply(map_age_group)\n",
    "\n",
    "# Apply the mapping function to update the 'age_group_clean' column based on age\n",
    "df['age_group_clean'] = df.apply(lambda row: map_age_to_clean(row['age']) if pd.isnull(row['age_group_clean']) else row['age_group_clean'], axis=1).astype('category')\n",
    "\n",
    "# Apply the mapping function to create the 'age_group_clean' column\n",
    "df['gaze'] = df['perspective'].apply(map_gaze).astype('category')\n",
    "\n",
    "# Apply the mapping function to update the 'perspective'\n",
    "df['perspective'] = df['perspective'].apply(map_perspective).astype('category') \n",
    "\n",
    "# Apply the mapping function to update the race\n",
    "df['race'] = df['race'].apply(map_race).astype('category')\n",
    "\n",
    "# Chantge 'auto_age' and 'auto_gender' to int\n",
    "df['auto_age'] = df['auto_age'].astype(int)\n",
    "df['auto_gender'] = df['auto_gender'].astype(int)\n",
    "df['auto_perspective'] = df['auto_perspective'].astype(int)\n",
    "\n",
    "# Save dataframe to csv\n",
    "df.to_csv(csv_file_out, index=False, sep=',', quotechar='\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
